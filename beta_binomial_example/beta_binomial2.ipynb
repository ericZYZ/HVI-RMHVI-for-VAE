{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('F:\\Cambridge\\Project\\MHMC-for-VAE/hmc')\n",
    "from hmc_base import *\n",
    "from hmc_unconstrained import *\n",
    "import autograd.numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import beta, comb, gamma\n",
    "from scipy.stats import multivariate_normal\n",
    "import operator as op\n",
    "import torch\n",
    "#from autograd.numpy import inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data pair list\n",
    "file = open(\"cancermortality.txt\", \"r\") \n",
    "data = (file.read()) \n",
    "tmp = data.split()\n",
    "tmp = tmp[2:len(tmp)]\n",
    "tmp = [int(e) for e in tmp]\n",
    "data_list = []\n",
    "for i in range(0, int(len(tmp)-1), 2):\n",
    "    data_list.append([tmp[i], tmp[i+1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get death number list\n",
    "death = []\n",
    "for i in range(len(data_list)):\n",
    "    death.append(data_list[i][0])\n",
    "# convert to np array\n",
    "death = np.array(death)\n",
    "\n",
    "# get risk number list\n",
    "risk = []\n",
    "for i in range(len(data_list)):\n",
    "    risk.append(data_list[i][1])\n",
    "# convert to np array\n",
    "risk = np.array(risk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_bound(y, n, mass_matrix, n_steps, z0_mean, z0_cov, v1_p_mean, v1_p_cov, v1_mean, v1_cov, joint_function):\n",
    "    # sample epsilson\n",
    "    eps_mean1 = np.array([0, 0])\n",
    "    eps_cov1 = np.identity(2)\n",
    "    eps1 = np.random.multivariate_normal(eps_mean1, eps_cov1)\n",
    "    \n",
    "    eps_mean2 = np.array([0, 0])\n",
    "    eps_cov2 = np.identity(2)\n",
    "    eps2 = np.random.multivariate_normal(eps_mean2, eps_cov2)\n",
    "    \n",
    "    eps_mean3 = np.array([0, 0])\n",
    "    eps_cov3 = np.identity(2)\n",
    "    eps3 = np.random.multivariate_normal(eps_mean3, eps_cov3)\n",
    "    \n",
    "    # Draw an initial random variable z0 \n",
    "    z0 = z0_mean + np.sqrt(z0_cov).dot(eps1)\n",
    "    #eta0 = (np.tanh(z0[0])+1)/200 #range(0, 0.01)\n",
    "    eta0 = z0[0]\n",
    "    k0 = z0[1]\n",
    "    \n",
    "    while((eta0<0) or (eta0>0.01) or (k0<=0)):\n",
    "        eps1 = np.random.multivariate_normal(eps_mean1, eps_cov1)\n",
    "        z0 = z0_mean + np.sqrt(z0_cov).dot(eps1)\n",
    "        eta0 = z0[0]\n",
    "        k0 = z0[1]\n",
    "    \n",
    "    print(eta0, k0)\n",
    "    # Init. lower bound\n",
    "    theta0 = torch.tensor([eta0, k0], requires_grad=True)\n",
    "    joint_t0 = joint_function(theta, y, n)\n",
    "    \n",
    "    L1 = torch.log(joint_t0)\n",
    "    L2 = torch.log(multivariate_normal.pdf(z0, z0_mean, z0_cov))\n",
    "    L = L1 - L2\n",
    "    \n",
    "    # define energy function\n",
    "    def posterior_energy(theta, cache):\n",
    "        eta = theta[0]\n",
    "        k = theta[1]\n",
    "        post = posterior(y, n, eta, k)\n",
    "        return -np.log(post)\n",
    "    \n",
    "    # MCMC steps\n",
    "    for i in range(1):\n",
    "        \n",
    "        grad_test = grad(joint_function)       # Obtain its gradient function\n",
    "        tt = grad_test(np.array([eta0, k0]),y,n) \n",
    "        print(str(tt))\n",
    "        # Draw vt'\n",
    "        vt_p = v1_p_mean + np.sqrt(v1_p_cov).dot(eps2)\n",
    "        \n",
    "        #init hmc sampler\n",
    "        sampler = IsotropicHmcSampler(posterior_energy, energy_grad=None, prng=None,\n",
    "                 mom_resample_coeff=0., dtype=np.float64)\n",
    "        pos_samples, mom_samples, ratio = sampler.get_samples(np.array([eta0, k0]), 0.1, n_steps, 1, mass_matrix)\n",
    "        z1 = pos_samples[0]\n",
    "        v1 = mom_samples[0]\n",
    "        #eta1 = z1[0]\n",
    "        #k1 = z1[1]\n",
    "        eta1 = z1[0]\n",
    "        k1 = z1[1]\n",
    "        \n",
    "        while((eta1<0) or (eta1>0.01) or (k1<=0)):\n",
    "            pos_samples, mom_samples, ratio = sampler.get_samples(np.array([eta0, k0]), 0.1, n_steps, 1, mass_matrix)\n",
    "            z1 = pos_samples[0]\n",
    "            v1 = mom_samples[0]\n",
    "            eta1 = z1[0]\n",
    "            k1 = z1[1]\n",
    "        \n",
    "        print(eta1, k1)\n",
    "        joint_t1 = joint_function(np.array([eta1, k1]), y, n)\n",
    "        rt = multivariate_normal.pdf(v1, v1_mean, v1_cov)\n",
    "        qt = multivariate_normal.pdf(vt_p, v1_p_mean, v1_p_cov)\n",
    "        \n",
    "        alpha = (joint_t1*rt)/(joint_t0*qt)\n",
    "        L = L + np.log(alpha)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return pos_samples, L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lbeta(a, b):\n",
    "    return torch.lgamma(a) + torch.lgamma(b) - torch.lgamma(a+b)\n",
    "\n",
    "def log_beta(a,b):\n",
    "    \n",
    "def prior_beta_binomial(theta):\n",
    "    eta = theta[0]\n",
    "    k = theta[1]\n",
    "    t1 = 1/(eta*(1-eta))\n",
    "    t2 = 1/(1+k)**2\n",
    "    return t1*t2\n",
    "\n",
    "def likelihood_beta_binomial(theta, y, n):\n",
    "    eta = theta[0]\n",
    "    k = theta[1]\n",
    "    n_data = y.shape[0]\n",
    "    result = 0.\n",
    "    for i in range(n_data):\n",
    "        n_comb = torch.tensor([comb(n[i], y[i])], requires_grad=True)\n",
    "        #one_likelihood = beta(k*eta+y[i], k*(1-eta)+n[i]-y[i])/beta(k*eta, k*(1-eta))\n",
    "        y_tensor = torch.tensor([float(y[i])], requires_grad=True)\n",
    "        n_tensor = torch.tensor([float(n[i])], requires_grad=True)\n",
    "        #one_likelihood = lbeta(torch.tensor([k*eta+y_tensor]), torch.tensor([k*(1-eta)+n_tensor-y_tensor]))-lbeta(torch.tensor([k*eta]), torch.tensor([k*(1-eta)]))\n",
    "        one_likelihood = lbeta((k*eta+y_tensor), (k*(1-eta)+n_tensor-y_tensor))-lbeta((k*eta), (k*(1-eta)))\n",
    "        one_likelihood = torch.log(n_comb)+one_likelihood\n",
    "        lbeta((k*eta+y_tensor), (k*(1-eta)+n_tensor-y_tensor))\n",
    "        print((k*eta+y_tensor))\n",
    "        print((k*(1-eta)+n_tensor-y_tensor))\n",
    "        print(lbeta((k*eta), (k*(1-eta))))\n",
    "        #print(beta(k*eta+y[i], k*(1-eta)+n[i]-y[i]))\n",
    "        #print(beta(k*eta, k*(1-eta)))\n",
    "        print(\"===================\")\n",
    "        print(one_likelihood)\n",
    "        result = result+one_likelihood\n",
    "    return result\n",
    "\n",
    "def joint_beta_binomial(theta, y, n):\n",
    "    #eta = theta[0]\n",
    "    #k = theta[1]\n",
    "    prior = prior_beta_binomial(theta)\n",
    "    print(\"prior \"+str(prior))\n",
    "    likelihood = likelihood_beta_binomial(theta, y, n)\n",
    "    print(\"like \"+str(likelihood))\n",
    "    return prior + likelihood\n",
    "\n",
    "def posterior(y, n, eta, k):\n",
    "    t1 = 1/(eta*(1-eta))\n",
    "    t2 = 1/np.power((1+k), 2)\n",
    "    t3 = np.prod(beta(k*eta+y, k*(1-eta)+n-y)/beta(k*eta, k*(1-eta)))\n",
    "    final = t1*t2*t3\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_bound(y, n, mass_matrix, n_steps, z0_mean, z0_cov, a1, b1, a2, b2, joint_function):\n",
    "    # sample epsilson\n",
    "    eps_mean1 = np.array([0, 0])\n",
    "    eps_cov1 = np.identity(2)\n",
    "    eps1 = np.random.multivariate_normal(eps_mean1, eps_cov1)\n",
    "    \n",
    "    eps_mean2 = np.array([0, 0])\n",
    "    eps_cov2 = np.identity(2)\n",
    "    eps2 = np.random.multivariate_normal(eps_mean2, eps_cov2)\n",
    "    \n",
    "    eps_mean3 = np.array([0, 0])\n",
    "    eps_cov3 = np.identity(2)\n",
    "    eps3 = np.random.multivariate_normal(eps_mean3, eps_cov3)\n",
    "    \n",
    "    # Draw an initial random variable z0 \n",
    "    z0 = z0_mean + torch.mm(torch.sqrt(z0_cov), eps1)\n",
    "    #eta0 = (np.tanh(z0[0])+1)/200 #range(0, 0.01)\n",
    "    eta0 = z0[0]\n",
    "    k0 = z0[1]\n",
    "    \n",
    "    while((eta0.item()<0) or (eta0.item()>0.01) or (k0.item()<=0)):\n",
    "        eps1 = np.random.multivariate_normal(eps_mean1, eps_cov1)\n",
    "        z0 = z0_mean + torch.mm(torch.sqrt(z0_cov), eps1)\n",
    "        eta0 = z0[0]\n",
    "        k0 = z0[1]\n",
    "    \n",
    "    # Init. lower bound\n",
    "    theta0 = torch.tensor([eta0, k0], requires_grad=True)\n",
    "    joint_t0 = joint_function(theta, y, n)\n",
    "    \n",
    "    L1 = torch.log(joint_t0)\n",
    "    L2 = torch.log(torch.tensor(multivariate_normal.pdf(z0.item(), z0_mean.item(), z0_cov.item())))\n",
    "    L = L1 - L2\n",
    "    \n",
    "    # define energy function\n",
    "    def posterior_energy(theta, cache):\n",
    "        eta = theta[0]\n",
    "        k = theta[1]\n",
    "        post = posterior(y, n, eta, k)\n",
    "        return -np.log(post)\n",
    "    \n",
    "    # MCMC steps\n",
    "    for i in range(1):\n",
    "        \n",
    "        grad_test = grad(joint_function)       # Obtain its gradient function\n",
    "        tt = grad_test(np.array([eta0, k0]),y,n) \n",
    "        print(str(tt))\n",
    "        # Draw vt'\n",
    "        vt_p = v1_p_mean + np.sqrt(v1_p_cov).dot(eps2)\n",
    "        \n",
    "        #init hmc sampler\n",
    "        sampler = IsotropicHmcSampler(posterior_energy, energy_grad=None, prng=None,\n",
    "                 mom_resample_coeff=0., dtype=np.float64)\n",
    "        pos_samples, mom_samples, ratio = sampler.get_samples(np.array([eta0, k0]), 0.1, n_steps, 1, mass_matrix)\n",
    "        z1 = pos_samples[0]\n",
    "        v1 = mom_samples[0]\n",
    "        #eta1 = z1[0]\n",
    "        #k1 = z1[1]\n",
    "        eta1 = z1[0]\n",
    "        k1 = z1[1]\n",
    "        \n",
    "        while((eta1<0) or (eta1>0.01) or (k1<=0)):\n",
    "            pos_samples, mom_samples, ratio = sampler.get_samples(np.array([eta0, k0]), 0.1, n_steps, 1, mass_matrix)\n",
    "            z1 = pos_samples[0]\n",
    "            v1 = mom_samples[0]\n",
    "            eta1 = z1[0]\n",
    "            k1 = z1[1]\n",
    "        \n",
    "        print(eta1, k1)\n",
    "        joint_t1 = joint_function(np.array([eta1, k1]), y, n)\n",
    "        rt = multivariate_normal.pdf(v1, v1_mean, v1_cov)\n",
    "        qt = multivariate_normal.pdf(vt_p, v1_p_mean, v1_p_cov)\n",
    "        \n",
    "        alpha = (joint_t1*rt)/(joint_t0*qt)\n",
    "        L = L + np.log(alpha)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return pos_samples, L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.0986], dtype=torch.float64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x =  torch.tensor([5.], requires_grad=True)\n",
    "y = np.array([3.])\n",
    "torch.log(torch.from_numpy(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'z0' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-db8d1a23a348>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmultivariate_normal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpdf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz0\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz0_mean\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz0_cov\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'z0' is not defined"
     ]
    }
   ],
   "source": [
    "x =  torch.tensor([[0., 1.],[1., 0.]], requires_grad=True)\n",
    "multivariate_normal.pdf(z0.item(), z0_mean.item(), z0_cov.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.00000e-02 *\n",
       "       [ 6.4176])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x =  torch.tensor([0.], requires_grad=True)\n",
    "y = torch.tensor([0.], requires_grad=True)\n",
    "z = torch.tensor([1.], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_bound(y, n, mass_matrix, n_steps, z0_mean, z0_cov, a1, b1, v1_p_cov, a2, b2, v1_cov, joint_function):\n",
    "    # sample epsilson\n",
    "    eps_mean1 = np.array([0, 0])\n",
    "    eps_cov1 = np.identity(2)\n",
    "    eps1 = np.random.multivariate_normal(eps_mean1, eps_cov1)\n",
    "    \n",
    "    eps_mean2 = np.array([0, 0])\n",
    "    eps_cov2 = np.identity(2)\n",
    "    eps2 = np.random.multivariate_normal(eps_mean2, eps_cov2)\n",
    "    \n",
    "    eps_mean3 = np.array([0, 0])\n",
    "    eps_cov3 = np.identity(2)\n",
    "    eps3 = np.random.multivariate_normal(eps_mean3, eps_cov3)\n",
    "    \n",
    "    # Draw an initial random variable z0 \n",
    "    z0 = z0_mean + np.sqrt(z0_cov).dot(eps1)\n",
    "    #eta0 = (np.tanh(z0[0])+1)/200 #range(0, 0.01)\n",
    "    eta0 = z0[0]\n",
    "    k0 = z0[1]\n",
    "    \n",
    "    while((eta0<0) or (eta0>0.01) or (k0<=0)):\n",
    "        eps1 = np.random.multivariate_normal(eps_mean1, eps_cov1)\n",
    "        z0 = z0_mean + np.sqrt(z0_cov).dot(eps1)\n",
    "        eta0 = z0[0]\n",
    "        k0 = z0[1]\n",
    "    \n",
    "    print(eta0, k0)\n",
    "    # Init. lower bound\n",
    "    theta0 = torch.tensor([eta0, k0], requires_grad=True)\n",
    "    joint_t0 = joint_function(theta0, y, n)\n",
    "    \n",
    "    # gradient\n",
    "    joint_t0.backward()\n",
    "    theta0_grad = theta0.grad.numpy()\n",
    "    \n",
    "    L1 = np.log(joint_t0.item())\n",
    "    L2 = np.log(multivariate_normal.pdf(z0, z0_mean, z0_cov))\n",
    "    L = L1 - L2\n",
    "    \n",
    "    # define energy function\n",
    "    def posterior_energy(theta, cache):\n",
    "        eta = theta[0]\n",
    "        k = theta[1]\n",
    "        post = posterior(y, n, eta, k)\n",
    "        return -np.log(post)\n",
    "    \n",
    "    # MCMC steps\n",
    "    for i in range(1):\n",
    "        \n",
    "        #grad_test = grad(joint_function)       # Obtain its gradient function\n",
    "        #tt = grad_test(np.array([eta0, k0]),y,n) \n",
    "         \n",
    "        v1_p_mean = a1*z0 + b1*theta0_grad # mean of guassian\n",
    "        # Draw vt'\n",
    "        vt_p = v1_p_mean + np.sqrt(v1_p_cov).dot(eps2)\n",
    "        \n",
    "        #init hmc sampler\n",
    "        sampler = IsotropicHmcSampler(posterior_energy, energy_grad=None, prng=None,\n",
    "                 mom_resample_coeff=0., dtype=np.float64)\n",
    "        pos_samples, mom_samples, ratio = sampler.get_samples(np.array([eta0, k0]), 0.1, n_steps, 1, mass_matrix)\n",
    "        z1 = pos_samples[0]\n",
    "        v1 = mom_samples[0]\n",
    "        #eta1 = z1[0]\n",
    "        #k1 = z1[1]\n",
    "        eta1 = z1[0]\n",
    "        k1 = z1[1]\n",
    "        \n",
    "        while((eta1<0) or (eta1>0.01) or (k1<=0)):\n",
    "            pos_samples, mom_samples, ratio = sampler.get_samples(np.array([eta0, k0]), 0.1, n_steps, 1, mass_matrix)\n",
    "            z1 = pos_samples[0]\n",
    "            v1 = mom_samples[0]\n",
    "            eta1 = z1[0]\n",
    "            k1 = z1[1]\n",
    "        \n",
    "        print(eta1, k1)\n",
    "        \n",
    "        theta1 = torch.tensor([eta1, k1], requires_grad=True)\n",
    "        joint_t1 = joint_function(theta1, y, n)\n",
    "        # gradient\n",
    "        joint_t1.backward()\n",
    "        theta1_grad = theta1.grad.numpy()\n",
    "        \n",
    "        #joint_t1 = joint_function(np.array([eta1, k1]), y, n)\n",
    "        v1_mean = a2*z1 + b2*theta1_grad # mean of guassian\n",
    "        rt = multivariate_normal.pdf(v1, v1_mean, v1_cov)\n",
    "        qt = multivariate_normal.pdf(vt_p, v1_p_mean, v1_p_cov)\n",
    "        \n",
    "        alpha = (joint_t1.item()*rt)/(joint_t0.item()*qt)\n",
    "        L = L + np.log(alpha)\n",
    "        \n",
    "    return pos_samples, L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "mass = 1.\n",
    "mass_matrix = mass*np.identity(2)\n",
    "z0_mean = np.array([0.0001,1000]) \n",
    "z0_cov = np.array([[1,0],[0,10]])\n",
    "v1_p_mean = np.array([0,0])\n",
    "v1_p_cov = np.identity(2)\n",
    "v1_mean = np.array([0,0])\n",
    "v1_cov = np.identity(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_samples, L = lower_bound(death, risk, mass_matrix, 5, z0_mean, z0_cov, v1_p_mean, v1_p_cov, v1_mean, v1_cov, joint_beta_binomial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00753876977123 1002.61587427\n",
      "prior tensor(1.00000e-04 *\n",
      "       1.3269)\n",
      "tensor([ 7.5585])\n",
      "tensor([ 2078.0574])\n",
      "tensor(-44.5513)\n",
      "===================\n",
      "tensor([-5.5532])\n",
      "tensor([ 7.5585])\n",
      "tensor([ 1850.0574])\n",
      "tensor(-44.5513)\n",
      "===================\n",
      "tensor([-4.6763])\n",
      "tensor([ 9.5585])\n",
      "tensor([ 4454.0571])\n",
      "tensor(-44.5513)\n",
      "===================\n",
      "tensor([-8.3435])\n",
      "tensor([ 7.5585])\n",
      "tensor([ 1652.0574])\n",
      "tensor(-44.5513)\n",
      "===================\n",
      "tensor([-3.8218])\n",
      "tensor([ 8.5585])\n",
      "tensor([ 2202.0574])\n",
      "tensor(-44.5513)\n",
      "===================\n",
      "tensor([-4.5727])\n",
      "tensor([ 8.5585])\n",
      "tensor([ 2019.0574])\n",
      "tensor(-44.5513)\n",
      "===================\n",
      "tensor([-3.9948])\n",
      "tensor([ 7.5585])\n",
      "tensor([ 1522.0574])\n",
      "tensor(-44.5513)\n",
      "===================\n",
      "tensor([-3.2046])\n",
      "tensor([ 9.5585])\n",
      "tensor([ 2661.0574])\n",
      "tensor(-44.5513)\n",
      "===================\n",
      "tensor([-4.8838])\n",
      "tensor([ 8.5585])\n",
      "tensor([ 1577.0574])\n",
      "tensor(-44.5513)\n",
      "===================\n",
      "tensor([-2.4487])\n",
      "tensor([ 10.5585])\n",
      "tensor([ 1574.0574])\n",
      "tensor(-44.5513)\n",
      "===================\n",
      "tensor([-1.8289])\n",
      "tensor([ 7.5585])\n",
      "tensor([ 1912.0574])\n",
      "tensor(-44.5513)\n",
      "===================\n",
      "tensor([-4.9243])\n",
      "tensor([ 8.5585])\n",
      "tensor([ 1851.0574])\n",
      "tensor(-44.5513)\n",
      "===================\n",
      "tensor([-3.4316])\n",
      "tensor([ 8.5585])\n",
      "tensor([ 1674.0574])\n",
      "tensor(-44.5513)\n",
      "===================\n",
      "tensor([-2.8046])\n",
      "tensor([ 8.5585])\n",
      "tensor([ 1911.0574])\n",
      "tensor(-44.5513)\n",
      "===================\n",
      "tensor([-3.6364])\n",
      "tensor([ 61.5585])\n",
      "tensor([ 54578.0586])\n",
      "tensor(-44.5513)\n",
      "===================\n",
      "tensor([inf.])\n",
      "tensor([ 7.5585])\n",
      "tensor([ 1869.0574])\n",
      "tensor(-44.5513)\n",
      "===================\n",
      "tensor([-4.7534])\n",
      "tensor([ 7.5585])\n",
      "tensor([ 1390.0574])\n",
      "tensor(-44.5513)\n",
      "===================\n",
      "tensor([-2.5190])\n",
      "tensor([ 8.5585])\n",
      "tensor([ 1575.0574])\n",
      "tensor(-44.5513)\n",
      "===================\n",
      "tensor([-2.4424])\n",
      "tensor([ 10.5585])\n",
      "tensor([ 1580.0574])\n",
      "tensor(-44.5513)\n",
      "===================\n",
      "tensor([-1.8371])\n",
      "tensor([ 7.5585])\n",
      "tensor([ 1378.0574])\n",
      "tensor(-44.5513)\n",
      "===================\n",
      "tensor([-2.4536])\n",
      "like tensor([inf.])\n",
      "0.00753876977123 1002.61587427\n",
      "prior tensor(1.00000e-04 *\n",
      "       1.3269)\n",
      "tensor([ 7.5585])\n",
      "tensor([ 2078.0574])\n",
      "tensor(-44.5513)\n",
      "===================\n",
      "tensor([-5.5532])\n",
      "tensor([ 7.5585])\n",
      "tensor([ 1850.0574])\n",
      "tensor(-44.5513)\n",
      "===================\n",
      "tensor([-4.6763])\n",
      "tensor([ 9.5585])\n",
      "tensor([ 4454.0571])\n",
      "tensor(-44.5513)\n",
      "===================\n",
      "tensor([-8.3435])\n",
      "tensor([ 7.5585])\n",
      "tensor([ 1652.0574])\n",
      "tensor(-44.5513)\n",
      "===================\n",
      "tensor([-3.8218])\n",
      "tensor([ 8.5585])\n",
      "tensor([ 2202.0574])\n",
      "tensor(-44.5513)\n",
      "===================\n",
      "tensor([-4.5727])\n",
      "tensor([ 8.5585])\n",
      "tensor([ 2019.0574])\n",
      "tensor(-44.5513)\n",
      "===================\n",
      "tensor([-3.9948])\n",
      "tensor([ 7.5585])\n",
      "tensor([ 1522.0574])\n",
      "tensor(-44.5513)\n",
      "===================\n",
      "tensor([-3.2046])\n",
      "tensor([ 9.5585])\n",
      "tensor([ 2661.0574])\n",
      "tensor(-44.5513)\n",
      "===================\n",
      "tensor([-4.8838])\n",
      "tensor([ 8.5585])\n",
      "tensor([ 1577.0574])\n",
      "tensor(-44.5513)\n",
      "===================\n",
      "tensor([-2.4487])\n",
      "tensor([ 10.5585])\n",
      "tensor([ 1574.0574])\n",
      "tensor(-44.5513)\n",
      "===================\n",
      "tensor([-1.8289])\n",
      "tensor([ 7.5585])\n",
      "tensor([ 1912.0574])\n",
      "tensor(-44.5513)\n",
      "===================\n",
      "tensor([-4.9243])\n",
      "tensor([ 8.5585])\n",
      "tensor([ 1851.0574])\n",
      "tensor(-44.5513)\n",
      "===================\n",
      "tensor([-3.4316])\n",
      "tensor([ 8.5585])\n",
      "tensor([ 1674.0574])\n",
      "tensor(-44.5513)\n",
      "===================\n",
      "tensor([-2.8046])\n",
      "tensor([ 8.5585])\n",
      "tensor([ 1911.0574])\n",
      "tensor(-44.5513)\n",
      "===================\n",
      "tensor([-3.6364])\n",
      "tensor([ 61.5585])\n",
      "tensor([ 54578.0586])\n",
      "tensor(-44.5513)\n",
      "===================\n",
      "tensor([inf.])\n",
      "tensor([ 7.5585])\n",
      "tensor([ 1869.0574])\n",
      "tensor(-44.5513)\n",
      "===================\n",
      "tensor([-4.7534])\n",
      "tensor([ 7.5585])\n",
      "tensor([ 1390.0574])\n",
      "tensor(-44.5513)\n",
      "===================\n",
      "tensor([-2.5190])\n",
      "tensor([ 8.5585])\n",
      "tensor([ 1575.0574])\n",
      "tensor(-44.5513)\n",
      "===================\n",
      "tensor([-2.4424])\n",
      "tensor([ 10.5585])\n",
      "tensor([ 1580.0574])\n",
      "tensor(-44.5513)\n",
      "===================\n",
      "tensor([-1.8371])\n",
      "tensor([ 7.5585])\n",
      "tensor([ 1378.0574])\n",
      "tensor(-44.5513)\n",
      "===================\n",
      "tensor([-2.4536])\n",
      "like tensor([inf.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:88: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "pos_samples, L = lower_bound(death, risk, mass_matrix, 5, z0_mean, z0_cov, 1, 1, v1_p_cov, 1, 1, v1_cov, joint_beta_binomial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
