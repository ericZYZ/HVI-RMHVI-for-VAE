{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('F:\\Cambridge\\Project\\MHMC-for-VAE\\change_of_variable')\n",
    "sys.path.append('F:\\Cambridge\\Project\\MHMC-for-VAE\\hmc_pytorch')\n",
    "from change_of_variable_pytorch import * \n",
    "from hmc_base_pytorch import *\n",
    "from hmc_unconstrained_pytorch import *\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "from torch.distributions.normal import Normal\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch.utils.data\n",
    "from torch import optim\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "import time\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#d = data.view(-1, 784)[j].view(1, 784)\n",
    "x = torch.tensor([[1.,2.],[3.,4.]])\n",
    "y = torch.tensor([[1.,2.],[3.,4.]])\n",
    "#one_new_data = torch.cat((d.float(), zt), 1) # append data with zt\n",
    "one_new_data = torch.cat((x, y), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.],\n",
       "        [ 3.,  4.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.,  1.,  2.],\n",
       "        [ 3.,  4.,  3.,  4.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = True\n",
    "batch_size = 64\n",
    "epochs = 10\n",
    "seed = 1\n",
    "log_interval = 10\n",
    "z_dim = 20\n",
    "\n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if cuda else {}\n",
    "\n",
    "train_data = datasets.MNIST('../data', train=True, download=True, transform=transforms.ToTensor())\n",
    "test_data = datasets.MNIST('../data', train=False, transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_data,\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_data,\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarization(data):\n",
    "    #s = np.random.uniform(size = data.shape)\n",
    "    s = 0.5*np.ones(shape = data.shape)\n",
    "    out = np.array(s<data).astype(float)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for batch_idx, (data, _) in enumerate(train_loader):\n",
    "    data = data.view(-1, 784).numpy()\n",
    "    bi_data = binarization(data)\n",
    "    d = torch.from_numpy(bi_data)\n",
    "    result.append(d)\n",
    "    #result.append(binarization(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 28])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.train_data[0].numpy().shape\n",
    "result[0][0].reshape(28,28).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n",
      "torch.Size([60000])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x28b0359f198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot one example\n",
    "print(train_data.train_data.size())                 # (60000, 28, 28)\n",
    "print(train_data.train_labels.size())               # (60000)\n",
    "#plt.imshow(train_data.train_data[0].numpy(), cmap='gray')\n",
    "plt.imshow(result[0][0].reshape(28,28), cmap='gray')\n",
    "plt.title('%i' % train_data.train_labels[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reparameterize(mu, logvar):\n",
    "    std = torch.exp(0.5*logvar)\n",
    "    eps = torch.randn_like(std)\n",
    "    return eps.mul(std).add_(mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_prior(z):\n",
    "    dim = z.shape[1]\n",
    "    mean = torch.zeros(dim).cuda()\n",
    "    cov = torch.eye(dim).cuda()\n",
    "    m = MultivariateNormal(mean, cov)\n",
    "    m.requires_grad=True\n",
    "    return m.log_prob(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.9189], device='cuda:0')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = torch.tensor([[0.]]).cuda()\n",
    "log_prior(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multivariate_normal_logpdf(mean, cov, x):\n",
    "    mean = mean.cuda()\n",
    "    cov = cov.cuda()\n",
    "    k = x.shape[0]\n",
    "    t1 = -0.5*(x - mean).view(1, k)@torch.inverse(cov)@(x - mean).view(k, 1)\n",
    "    t2 = 0.5*k*torch.log(2*torch.tensor([math.pi]).cuda()) + 0.5*torch.log(torch.det(cov))\n",
    "    return t1 - t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multivariate_normal_diagonal_logpdf(mean, cov_diag, x):\n",
    "    mean = mean.cuda()\n",
    "    cov_diag = cov_diag.cuda()\n",
    "    n = x.shape[0] # number of samples\n",
    "    k = x.shape[1] # dimension\n",
    "    t1 = -0.5*(x - mean)*(1/cov_diag)*(x-mean)\n",
    "    t1 = torch.sum(t1, dim=1)\n",
    "    #t2 = 0.5*k*torch.log(2*torch.tensor([math.pi]).cuda()) + 0.5*torch.log(torch.prod(cov_diag,1)).cuda()\n",
    "    t2 = 0.5*k*torch.log(2*torch.tensor([math.pi]).cuda()) + 0.5*torch.sum(torch.log(cov_diag)).cuda()\n",
    "    return t1 - t2\n",
    "    #return t1 - t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.7568, -3.7568], device='cuda:0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = torch.tensor([[0.,0.,0.],[0.,0.,0.]]).cuda()\n",
    "cov_diag = torch.tensor([[1.,1.,1.],[1.,1.,1.]]).cuda()\n",
    "x = torch.tensor([[0.,0.,0.],[1.,1.,0.]]).cuda()\n",
    "multivariate_normal_diagonal_logpdf(mean, cov_diag, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.7568]], device='cuda:0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = torch.tensor([0.,0.,0.]).cuda()\n",
    "cov = torch.eye(3).cuda()\n",
    "x = torch.tensor([0.,0.,0.]).cuda()\n",
    "multivariate_normal_logpdf(mean, cov, x)-torch.tensor([1.]).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-80c53c792bb2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mcov\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1.\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1.\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1.\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0.\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmultivariate_normal_diagonal_logpdf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcov\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-5-4eb90646f4a0>\u001b[0m in \u001b[0;36mmultivariate_normal_diagonal_logpdf\u001b[1;34m(mean, cov_diag, x)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mcov_diag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcov_diag\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# number of samples\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# dimension\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mt1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mcov_diag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mt1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "mean = torch.tensor([0.,0.,0.]).cuda()\n",
    "cov = torch.tensor([1.,1.,1.]).cuda()\n",
    "x = torch.tensor([0.,0.,0.]).cuda()\n",
    "multivariate_normal_diagonal_logpdf(mean, cov, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-15.3818,  -3.7568], device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_prior(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.7568]], device='cuda:0')"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = torch.tensor([0.,0.,0.]).cuda()\n",
    "cov = torch.eye(3).cuda()\n",
    "x = torch.tensor([1.,1.,0.]).cuda()\n",
    "multivariate_normal_logpdf(mean, cov, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.,  1.,  4.])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov_diag = torch.tensor([[1.,2.,1.],[1.,1.,1.],[4.,1.,1.]])\n",
    "torch.prod(cov_diag,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[1.,1.,1.],[2.,1.,0.]])\n",
    "y = torch.tensor([[2.,0.,0.],[1.,1.,1.]])\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 3])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = torch.tensor([[[0.,0.,0.]],[[0.,1.,0.]],[[0.,0.,0.]]])\n",
    "mean.shape\n",
    "cov = torch.tensor([[[1.,0.,0.],[0.,1.,0.],[0.,0.,1.]],[[1.,0.,0.],[0.,1.,0.],[0.,0.,1.]],[[1.,0.,0.],[0.,1.,0.],[0.,0.,1.]]])\n",
    "cov.shape\n",
    "x = torch.tensor([[[0., 2.,0.]],[[0., 0.,0.]],[[0., 0.,0.]]])\n",
    "mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 2])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = torch.tensor([[[0.,0.]],[[0.,1.]],[[0.,0.]]])\n",
    "mean.shape\n",
    "cov = torch.tensor([[[1.,0.],[0.,1.]],[[1.,0.],[0.,1.]],[[1.,0.],[0.,1.]]])\n",
    "cov.shape\n",
    "x = torch.tensor([[[0., 2.]],[[0., 0.]],[[0., 0.]]])\n",
    "mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.8379, -3.8379, -3.8379],\n",
       "        [-2.3379, -2.3379, -2.3379],\n",
       "        [-1.8379, -1.8379, -1.8379]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = MultivariateNormal(mean, cov)\n",
    "tt = m.log_prob(x)\n",
    "tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-2.7568])\n"
     ]
    }
   ],
   "source": [
    "mean = torch.tensor([[0., 0.,0.]])\n",
    "#mean = torch.tensor([[0.],[0.]])\n",
    "cov = torch.eye(3)\n",
    "x = torch.tensor([0., 0., 0.])\n",
    "m = MultivariateNormal(mean, cov)\n",
    "print(m.log_prob(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(decoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(z_dim, 400)\n",
    "        self.fc2 = nn.Linear(400, 784)\n",
    "    # single hidden layer\n",
    "    def forward(self, x):\n",
    "        #x = x.view(-1, 784)\n",
    "        h1 = F.relu(self.fc1(x))\n",
    "        return F.sigmoid(self.fc2(h1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class q_z0(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(q_z0, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 300)\n",
    "        #self.fc2 = nn.Linear(300, 300)\n",
    "        self.fc31 = nn.Linear(300, z_dim)\n",
    "        self.fc32 = nn.Linear(300, z_dim)\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)\n",
    "        h1 = F.relu(self.fc1(x))\n",
    "        #h2 = F.relu(self.fc2(h1))\n",
    "        logvar = self.fc31(h1)\n",
    "        mu = self.fc32(h1)\n",
    "        return mu, logvar\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class r_v(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(r_v, self).__init__()\n",
    "        self.fc1 = nn.Linear(z_dim + 784, 300)\n",
    "        self.fc21 = nn.Linear(300, z_dim)\n",
    "        self.fc22 = nn.Linear(300, z_dim)\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784 + z_dim)\n",
    "        h1 = F.softplus(self.fc1(x))\n",
    "        logvar = self.fc21(h1)\n",
    "        mu = self.fc22(h1)\n",
    "        return mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class q_v(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(q_v, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 300)\n",
    "        # no need to output mu because the mean of momentum is default 0\n",
    "        self.fc21 = nn.Linear(300, z_dim)\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)\n",
    "        h1 = F.softplus(self.fc1(x))\n",
    "        logvar = self.fc21(h1)\n",
    "        return logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.9189, -0.9189])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = torch.zeros(2,1)\n",
    "cov = torch.eye(2)\n",
    "m = MultivariateNormal(mean, cov)\n",
    "x = torch.tensor([0.,0.]) \n",
    "m.log_prob(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = decoder().to(device)\n",
    "q_z0 = q_z0().to(device)\n",
    "r_v = r_v().to(device)\n",
    "q_v = q_v().to(device)\n",
    "log_mass_diag = torch.randn(z_dim, requires_grad=True)\n",
    "#mass = torch.randn(z_dim, requires_grad=True)\n",
    "#mass = torch.eye(z_dim, requires_grad=True)\n",
    "#mass_cuda = mass.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_bound(decoder, q_z0, r_v, data, log_mass_diag, T):\n",
    "    batch_size = data.view(-1, 784).shape[0]\n",
    "    data = data.to(device)\n",
    "    \n",
    "    #mu_z0 = q_z0_mean.repeat(batch_size,1).cuda()\n",
    "    #logvar_z0 = q_z0_logvar.repeat(batch_size,1).cuda()\n",
    "    \n",
    "    \n",
    "    mu_z0, logvar_z0 = q_z0(data)\n",
    "    var_z0 = torch.exp(logvar_z0)\n",
    "    print(\"mu_z0: \"+str(mu_z0.shape))\n",
    "    #print(logvar_z0.shape)\n",
    "\n",
    "    # sample z0\n",
    "    z0 = reparameterize(mu_z0, logvar_z0)\n",
    "    print(\"z0: \" + str(z0.shape))\n",
    "    #print(z0)\n",
    "\n",
    "    # get joint probaility p(x, z0)\n",
    "    log_prior_z0 = log_prior(z0)\n",
    "    #print(\"log_prior_z0: \" + str(log_prior_z0.shape))\n",
    "    decoder_output = decoder(z0)\n",
    "    #print(\"decoder_output: \" + str(decoder_output.shape))\n",
    "    log_likelihood = 0. - F.binary_cross_entropy(decoder_output, data.view(-1, 784).float(), size_average=False, reduce=False)\n",
    "    #print(\"log_likelihood: \" + str(log_likelihood.shape))\n",
    "    log_likelihood = torch.sum(log_likelihood, dim = 1)\n",
    "    #print(\"log_likelihood: \" + str(log_likelihood.shape))\n",
    "    log_joint = log_prior_z0 + log_likelihood\n",
    "    #print(\"log_joint: \" + str(log_joint.shape))\n",
    "\n",
    "    # get log q_z0\n",
    "    log_q_z0 = multivariate_normal_diagonal_logpdf(mu_z0, var_z0, z0)\n",
    "\n",
    "    # initial L for 128 samples\n",
    "    L = log_joint - log_q_z0.view(batch_size)\n",
    "    L = torch.sum(L)\n",
    "    #print(\"L \"+str(L))\n",
    "    #print(L.shape)\n",
    "\n",
    "    #print(\"====================================\")\n",
    "    for i in range(T):\n",
    "        # sample v1\n",
    "        mass_diag = torch.exp(log_mass_diag)\n",
    "        mass_matrix = torch.diag(mass_diag)\n",
    "        mass_matrix.cuda()\n",
    "        print(log_mass_diag)\n",
    "        \n",
    "        #var_v1_matrix = torch.inverse(mass_matrix)\n",
    "        #var_v1_diag = torch.diag(var_v1_matrix)\n",
    "        #logvar_v1_diag = torch.log(var_v1_diag)\n",
    "        \n",
    "        \n",
    "        logvar_v1_diag = -log_mass_diag\n",
    "        var_v1_diag = torch.exp(logvar_v1_diag)\n",
    "        \n",
    "        \n",
    "        \n",
    "        logvar_v1 = logvar_v1_diag.repeat(batch_size,1).cuda()\n",
    "        var_v1 = var_v1_diag.repeat(batch_size,1).cuda()\n",
    "        mu_v1 = torch.zeros(logvar_v1.shape[0], logvar_v1.shape[1]).cuda()\n",
    "        v1 = reparameterize(mu_v1, logvar_v1)\n",
    "        #print(v1)\n",
    "        \n",
    "        # get q_v1\n",
    "        \n",
    "        log_q_v1 = multivariate_normal_diagonal_logpdf(mu_v1, var_v1 ,v1)\n",
    "        \n",
    "\n",
    "        log_joint_t = torch.zeros(0).cuda() # list of all the joint\n",
    "        log_r_vt = torch.zeros(0).cuda()\n",
    "        alpha = torch.tensor([0.]).cuda() # lower bound for each batch (128 samples)\n",
    "        for j in range(batch_size):\n",
    "            def energy_function(z, cache):\n",
    "                z.retain_grad()\n",
    "                z = z.view(1, z.shape[0])\n",
    "                z = z.cuda()\n",
    "                one_log_prior = log_prior(z)\n",
    "                decoder_output = decoder(z)\n",
    "                one_log_likelihood = 0. - F.binary_cross_entropy(decoder_output, data.view(-1, 784)[j].float(), size_average=False, reduce=False)\n",
    "                #print(one_log_likelihood.shape)\n",
    "                one_log_likelihood = torch.sum(one_log_likelihood, dim = 1)\n",
    "                one_log_joint = one_log_prior + one_log_likelihood\n",
    "                return 0 - one_log_joint\n",
    "            sampler = IsotropicHmcSampler(energy_function, energy_grad=None, prng=None,\n",
    "                                          mom_resample_coeff=1., dtype=np.float64)\n",
    "            init = torch.zeros(z_dim).cuda()\n",
    "            \n",
    "            pos_samples, mom_samples, ratio = sampler.get_samples(init, 0.1, 3, 2, mass_matrix, mom = v1[j].view(z_dim))\n",
    "            #print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~`\")\n",
    "            #print(pos_samples[1].shape)\n",
    "\n",
    "            # get joint probaility p(x, zt)\n",
    "            zt = pos_samples[1].cuda()\n",
    "            vt = mom_samples[1].cuda()\n",
    "            zt = zt.view(1, zt.shape[0])\n",
    "            vt = vt.view(vt.shape[0])\n",
    "\n",
    "            # get joint probaility p(x, zt)\n",
    "            one_log_prior_zt = log_prior(zt)\n",
    "            #print(\"one_log_prior_zt: \" + str(one_log_prior_zt.shape))\n",
    "            one_decoder_output_t = decoder(zt)\n",
    "            #print(\"one_decoder_output_t: \" + str(one_decoder_output_t.shape))\n",
    "            one_log_likelihood_t = 0. - F.binary_cross_entropy(one_decoder_output_t, data.view(-1, 784)[j].float(), size_average=False, reduce=False)\n",
    "            one_log_likelihood_t = torch.sum(one_log_likelihood_t, dim = 1)\n",
    "            #print(\"one_log_likelihood_t: \" + str(one_log_likelihood_t.shape))\n",
    "            one_log_joint_t = one_log_prior_zt + one_log_likelihood_t\n",
    "            #print(\"one_log_joint_t: \" + str(one_log_joint_t.shape))\n",
    "            log_joint_t = torch.cat((log_joint_t, one_log_joint_t), 0)\n",
    "\n",
    "            # get r_vt\n",
    "            d = data.view(-1, 784)[j].view(1, 784)\n",
    "            one_new_data = torch.cat((d.float(), zt), 1) # append data with zt\n",
    "            one_mu_vt, one_logvar_vt = r_v(one_new_data)\n",
    "            one_var_vt = torch.exp(one_logvar_vt)\n",
    "            one_mu_vt = one_mu_vt.view(one_mu_vt.shape[1])\n",
    "            one_cov = torch.diag(one_var_vt.view(one_var_vt.shape[1]))\n",
    "            #m = MultivariateNormal(one_mu_vt, one_cov)\n",
    "            #one_log_r_vt = m.log_prob(vt).view(1)\n",
    "            one_log_r_vt = multivariate_normal_logpdf(one_mu_vt, one_cov, vt)\n",
    "            log_r_vt = torch.cat((log_r_vt, one_log_r_vt), 0)\n",
    "            \n",
    "\n",
    "            # get L for each sample\n",
    "            one_log_alpha = log_joint_t[j] + log_r_vt[j] - log_joint[j] - log_q_v1[j]\n",
    "            #print(\"one log alpha: \"+str(one_log_alpha))\n",
    "            #one_log_alpha = torch.log(one_alpha)\n",
    "            L = L + one_log_alpha\n",
    "            #alpha = alpha + one_alpha\n",
    "        #L = L + torch.log(alpha)\n",
    "\n",
    "    #print(\"~~~~~~~~~~~~~~~~~~~ new L \" + str(L) + \" ~~~~~~~~~~~~~~~~~~~\")\n",
    "    return L/batch_size    \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([nan., nan., nan., nan., nan., nan., nan., nan., nan., nan.,\n",
       "        nan., nan., nan., nan., nan., nan., nan., nan., nan., nan.])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(q_z0.parameters())\n",
    "log_mass_diag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++ 0 ++++++++++\n",
      "mu_z0: torch.Size([64, 20])\n",
      "z0: torch.Size([64, 20])\n",
      "tensor([-2.6590,  0.6581, -0.5448,  1.5155, -0.7538, -0.5816, -0.7492,\n",
      "        -1.2490,  0.1221, -1.2655,  0.8417,  1.1234, -0.1018,  0.7371,\n",
      "         0.4650,  1.1652,  1.5014,  1.1545,  1.3702, -1.3800])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1474: UserWarning: Using a target size (torch.Size([784])) that is different to the input size (torch.Size([1, 784])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-3aeba099b65a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0moptimizer2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0moptimizer3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mL\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlower_bound\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mq_z0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr_v\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_mass_diag\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mL\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-4ad4c7e8e411>\u001b[0m in \u001b[0;36mlower_bound\u001b[1;34m(decoder, q_z0, r_v, data, log_mass_diag, T)\u001b[0m\n\u001b[0;32m     86\u001b[0m             \u001b[0minit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m             \u001b[0mpos_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmom_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mratio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msampler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmass_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m             \u001b[1;31m#print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~`\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m             \u001b[1;31m#print(pos_samples[1].shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Cambridge\\Project\\MHMC-for-VAE\\hmc_pytorch\\hmc_base_pytorch.py\u001b[0m in \u001b[0;36mget_samples\u001b[1;34m(self, pos, dt, n_step_per_sample, n_sample, mass, mom)\u001b[0m\n\u001b[0;32m    102\u001b[0m                 pos_p, mom_p, cache_p = self.simulate_dynamic(\n\u001b[0;32m    103\u001b[0m                     \u001b[0mn_step_per_sample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos_samples\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m                     mom_samples[s-1], mass, cache)\n\u001b[0m\u001b[0;32m    105\u001b[0m                 \u001b[1;31m#print(\"========== 2nd hamiltonian ==============\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m                 \u001b[0mhamiltonian_p\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhamiltonian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos_p\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmom_p\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmass\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcache_p\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Cambridge\\Project\\MHMC-for-VAE\\hmc_pytorch\\hmc_unconstrained_pytorch.py\u001b[0m in \u001b[0;36msimulate_dynamic\u001b[1;34m(self, n_step, dt, pos, mom, mass, cache)\u001b[0m\n\u001b[0;32m     43\u001b[0m             \u001b[0mpos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpos\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdt\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmom\u001b[0m\u001b[1;33m@\u001b[0m\u001b[0mmass_inv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m                 \u001b[0mmom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmom\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mdt\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menergy_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m                 \u001b[0mpos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpos\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdt\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmom\u001b[0m\u001b[1;33m@\u001b[0m\u001b[0mmass_inv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m             \u001b[0mmom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmom\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m0.5\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mdt\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menergy_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Cambridge\\Project\\MHMC-for-VAE\\hmc_pytorch\\hmc_base_pytorch.py\u001b[0m in \u001b[0;36mgradient\u001b[1;34m(pos, cache)\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[1;31m#print(\"------calling energy function------\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[0mpos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretain_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menergy_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-4ad4c7e8e411>\u001b[0m in \u001b[0;36menergy_function\u001b[1;34m(z, cache)\u001b[0m\n\u001b[0;32m     75\u001b[0m                 \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m                 \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m                 \u001b[0mone_log_prior\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlog_prior\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m                 \u001b[0mdecoder_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m                 \u001b[0mone_log_likelihood\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecoder_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m784\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-4da50e686a12>\u001b[0m in \u001b[0;36mlog_prior\u001b[1;34m(z)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMultivariateNormal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcov\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\distributions\\multivariate_normal.py\u001b[0m in \u001b[0;36mlog_prob\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m    180\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_sample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[0mdiff\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mM\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_batch_mahalanobis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscale_tril\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiff\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[0mlog_det\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_batch_diag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscale_tril\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m0.5\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mM\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlog_det\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\distributions\\utils.py\u001b[0m in \u001b[0;36m__get__\u001b[1;34m(self, instance, obj_type)\u001b[0m\n\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minstance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m         \u001b[0msetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\distributions\\multivariate_normal.py\u001b[0m in \u001b[0;36mscale_tril\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mlazy_property\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mscale_tril\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 151\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_batch_potrf_lower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcovariance_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mlazy_property\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\distributions\\multivariate_normal.py\u001b[0m in \u001b[0;36m_batch_potrf_lower\u001b[1;34m(bmat)\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbmat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[0mcholesky\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpotrf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mupper\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mC\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbmat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcholesky\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbmat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "params1 = list(decoder.parameters())+list(r_v.parameters())\n",
    "\n",
    "optimizer1 = optim.Adam(params1, lr=0.0001, weight_decay=1e-5)\n",
    "optimizer2 = optim.Adam([log_mass_diag], lr=0.0001)\n",
    "optimizer3 = optim.Adam(q_z0.parameters(), lr=0.0001, weight_decay=1e-4)\n",
    "nn.utils.clip_grad_norm_(q_z0.parameters(), 50)\n",
    "\n",
    "for i in range(len(result)):\n",
    "    print(\"++++++++++ \" + str(i) + \" ++++++++++\")\n",
    "    \n",
    "    data = result[i].float()\n",
    "    optimizer1.zero_grad()\n",
    "    optimizer2.zero_grad()\n",
    "    optimizer3.zero_grad()\n",
    "    L = lower_bound(decoder, q_z0, r_v, data, log_mass_diag, 1)\n",
    "    loss = 0. - L\n",
    "    loss.backward()\n",
    "    #print('weight grad after backward')\n",
    "    #print(net.conv1.bias.grad)\n",
    "    #print(q_z0.fc1.weight.grad)\n",
    "    #print(q_z0.fc31.weight.grad)\n",
    "    #print(q_z0.fc32.weight.grad)\n",
    "    optimizer1.step()\n",
    "    optimizer2.step()\n",
    "    optimizer3.step()\n",
    "    print(L.item())\n",
    "print(L.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++ 0 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1474: UserWarning: Using a target size (torch.Size([784])) that is different to the input size (torch.Size([1, 784])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-540.8672485351562\n",
      "++++++++++ 1 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-572.6387939453125\n",
      "++++++++++ 2 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-588.7979125976562\n",
      "++++++++++ 3 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-579.67236328125\n",
      "++++++++++ 4 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-559.671142578125\n",
      "++++++++++ 5 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-544.0812377929688\n",
      "++++++++++ 6 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-544.778076171875\n",
      "++++++++++ 7 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-516.0226440429688\n",
      "++++++++++ 8 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-505.8245544433594\n",
      "++++++++++ 9 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-497.9623107910156\n",
      "++++++++++ 10 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-487.72406005859375\n",
      "++++++++++ 11 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-463.9438781738281\n",
      "++++++++++ 12 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-466.0975341796875\n",
      "++++++++++ 13 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-452.3597717285156\n",
      "++++++++++ 14 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-450.99078369140625\n",
      "++++++++++ 15 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-429.5964050292969\n",
      "++++++++++ 16 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-434.8597412109375\n",
      "++++++++++ 17 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-417.3406677246094\n",
      "++++++++++ 18 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-407.9772033691406\n",
      "++++++++++ 19 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-411.21466064453125\n",
      "++++++++++ 20 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-403.7613525390625\n",
      "++++++++++ 21 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-404.00726318359375\n",
      "++++++++++ 22 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-399.34600830078125\n",
      "++++++++++ 23 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-390.32379150390625\n",
      "++++++++++ 24 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-378.6222229003906\n",
      "++++++++++ 25 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-375.39520263671875\n",
      "++++++++++ 26 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-372.48175048828125\n",
      "++++++++++ 27 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-361.93707275390625\n",
      "++++++++++ 28 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-359.9893493652344\n",
      "++++++++++ 29 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-373.8966979980469\n",
      "++++++++++ 30 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-359.6930236816406\n",
      "++++++++++ 31 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-350.148681640625\n",
      "++++++++++ 32 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-361.45147705078125\n",
      "++++++++++ 33 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-364.83154296875\n",
      "++++++++++ 34 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-356.56005859375\n",
      "++++++++++ 35 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-344.2277526855469\n",
      "++++++++++ 36 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-341.2362365722656\n",
      "++++++++++ 37 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-362.663330078125\n",
      "++++++++++ 38 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-345.8728332519531\n",
      "++++++++++ 39 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-363.71917724609375\n",
      "++++++++++ 40 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-352.9364318847656\n",
      "++++++++++ 41 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-353.8746337890625\n",
      "++++++++++ 42 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-342.87945556640625\n",
      "++++++++++ 43 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-326.8343811035156\n",
      "++++++++++ 44 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-360.9006042480469\n",
      "++++++++++ 45 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-344.5437927246094\n",
      "++++++++++ 46 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-338.8890686035156\n",
      "++++++++++ 47 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-325.91522216796875\n",
      "++++++++++ 48 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-219-1e33a8fd0192>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0moptimizer1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0moptimizer2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mL\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlower_bound\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mq_z0_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mq_z0_logvar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr_v\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_mass_diag\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mL\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-218-000e7370f612>\u001b[0m in \u001b[0;36mlower_bound\u001b[1;34m(decoder, q_z0_mean, q_z0_logvar, r_v, data, log_mass_diag, T)\u001b[0m\n\u001b[0;32m    114\u001b[0m             \u001b[0minit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m             \u001b[0mpos_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmom_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mratio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msampler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmass_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m             \u001b[1;31m#print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~`\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m             \u001b[1;31m#print(pos_samples[1].shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Cambridge\\Project\\MHMC-for-VAE\\hmc_pytorch\\hmc_base_pytorch.py\u001b[0m in \u001b[0;36mget_samples\u001b[1;34m(self, pos, dt, n_step_per_sample, n_sample, mass, mom)\u001b[0m\n\u001b[0;32m    112\u001b[0m             \u001b[1;31m# Metropolis-Hastings accept step on proposed update\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             if (proposal_successful and self.prng.uniform() <\n\u001b[1;32m--> 114\u001b[1;33m                     torch.exp(hamiltonian_c - hamiltonian_p).item()):\n\u001b[0m\u001b[0;32m    115\u001b[0m                 \u001b[1;31m# accept move\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m                 \u001b[0mpos_samples\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmom_samples\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcache\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpos_p\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmom_p\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcache_p\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "params1 = list(decoder.parameters())+list(q_z0.parameters())+list(r_v.parameters())\n",
    "optimizer1 = optim.Adam(params1, lr=0.0003)\n",
    "optimizer2 = optim.Adam([log_mass_diag, q_z0_mean, q_z0_logvar], lr=0.0003)\n",
    "nn.utils.clip_grad_norm_(q_z0.parameters(), 50)\n",
    "for batch_idx, (data, _) in enumerate(train_loader):\n",
    "    print(\"++++++++++ \" + str(batch_idx) + \" ++++++++++\")\n",
    "    \n",
    "    optimizer1.zero_grad()\n",
    "    optimizer2.zero_grad()\n",
    "    L = lower_bound(decoder, q_z0_mean, q_z0_logvar, r_v, data, log_mass_diag, 1)\n",
    "    loss = 0. - L\n",
    "    loss.backward()\n",
    "    #print('weight grad after backward')\n",
    "    #print(net.conv1.bias.grad)\n",
    "    #print(q_z0.fc1.weight.grad)\n",
    "    #print(q_z0.fc31.weight.grad)\n",
    "    #print(q_z0.fc32.weight.grad)\n",
    "    optimizer1.step()\n",
    "    optimizer2.step()\n",
    "    print(L.item())\n",
    "print(L.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "params argument given to the optimizer should be an iterable of Tensors or dicts, but got torch.FloatTensor",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-143b7071f5f2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m#x = Variable(torch.randn(5))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\optim\\sgd.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, params, lr, momentum, dampening, weight_decay, nesterov)\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnesterov\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmomentum\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mdampening\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Nesterov momentum requires a momentum and zero dampening\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSGD\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setstate__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\optim\\optimizer.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, params, defaults)\u001b[0m\n\u001b[0;32m     29\u001b[0m             raise TypeError(\"params argument given to the optimizer should be \"\n\u001b[0;32m     30\u001b[0m                             \u001b[1;34m\"an iterable of Tensors or dicts, but got \"\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m                             torch.typename(params))\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: params argument given to the optimizer should be an iterable of Tensors or dicts, but got torch.FloatTensor"
     ]
    }
   ],
   "source": [
    "#params = mass_diag\n",
    "\n",
    "\n",
    "#optimizer = optim.Adam(params, lr=1e-3)\n",
    "\n",
    "w = torch.randn([3,5], requires_grad=True)\n",
    "b = torch.randn(3, requires_grad=True)\n",
    "#x = Variable(torch.randn(5))\n",
    "\n",
    "optimizer = optim.SGD([w], lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([400, 20])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(decoder.parameters())\n",
    "params[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(decoder.parameters())[0]\n",
    "#list(mass_diag)[0]\n",
    "mass_diag.is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 784])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt = torch.ones(1, 784).cuda()\n",
    "print(tt.shape)\n",
    "torch.sum(tt, dim=1)\n",
    "tt.is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[0.1, 0.1],[0.1,0.1],[0.1,0.1]])\n",
    "y = torch.tensor([[0.5, 0.5],[0.5,0.5],[1.,1.]])\n",
    "L = F.binary_cross_entropy(y, x, size_average=False, reduce=False)\n",
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Lapack Error getrf : U(2,2) is 0, U is singular at c:\\programdata\\miniconda3\\conda-bld\\pytorch_1524546354046\\work\\aten\\src\\th\\generic/THTensorLapack.c:514",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-dee977365fee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: Lapack Error getrf : U(2,2) is 0, U is singular at c:\\programdata\\miniconda3\\conda-bld\\pytorch_1524546354046\\work\\aten\\src\\th\\generic/THTensorLapack.c:514"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[0.1, 0.1],[0.1,0.1]])\n",
    "torch.inverse(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
