{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('F:\\Cambridge\\Project\\MHMC-for-VAE\\change_of_variable')\n",
    "sys.path.append('F:\\Cambridge\\Project\\MHMC-for-VAE\\hmc_pytorch')\n",
    "from change_of_variable_pytorch import * \n",
    "from hmc_base_pytorch import *\n",
    "from hmc_unconstrained_pytorch import *\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "from torch.distributions.normal import Normal\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch.utils.data\n",
    "from torch import optim\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "import time\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = True\n",
    "batch_size = 64\n",
    "epochs = 10\n",
    "seed = 1\n",
    "log_interval = 10\n",
    "z_dim = 20\n",
    "\n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if cuda else {}\n",
    "\n",
    "train_data = datasets.MNIST('../data', train=True, download=True, transform=transforms.ToTensor())\n",
    "test_data = datasets.MNIST('../data', train=False, transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_data,\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_data,\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarization(data):\n",
    "    s = np.random.uniform(size = data.shape)\n",
    "    out = np.array(s<data).astype(float)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for batch_idx, (data, _) in enumerate(train_loader):\n",
    "    data = data.view(-1, 784).numpy()\n",
    "    bi_data = binarization(data)\n",
    "    d = torch.from_numpy(bi_data)\n",
    "    result.append(d)\n",
    "    #result.append(binarization(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 784])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.train_data[0].numpy().shape\n",
    "result[0][0].reshape(28,28).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n",
      "torch.Size([60000])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1bf0f99c240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot one example\n",
    "print(train_data.train_data.size())                 # (60000, 28, 28)\n",
    "print(train_data.train_labels.size())               # (60000)\n",
    "#plt.imshow(train_data.train_data[0].numpy(), cmap='gray')\n",
    "plt.imshow(result[0][0].reshape(28,28), cmap='gray')\n",
    "plt.title('%i' % train_data.train_labels[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reparameterize(mu, logvar):\n",
    "    std = torch.exp(0.5*logvar)\n",
    "    eps = torch.randn_like(std)\n",
    "    return eps.mul(std).add_(mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_prior(z):\n",
    "    dim = z.shape[1]\n",
    "    mean = torch.zeros(dim).cuda()\n",
    "    cov = torch.eye(dim).cuda()\n",
    "    m = MultivariateNormal(mean, cov)\n",
    "    m.requires_grad=True\n",
    "    return m.log_prob(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multivariate_normal_logpdf(mean, cov, x):\n",
    "    mean = mean.cuda()\n",
    "    cov = cov.cuda()\n",
    "    k = x.shape[0]\n",
    "    t1 = -0.5*(x - mean).view(1, k)@torch.inverse(cov)@(x - mean).view(k, 1)\n",
    "    t2 = 0.5*k*torch.log(2*torch.tensor([math.pi]).cuda()) + 0.5*torch.log(torch.det(cov))\n",
    "    return t1 - t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multivariate_normal_diagonal_logpdf(mean, cov_diag, x):\n",
    "    mean = mean.cuda()\n",
    "    cov_diag = cov_diag.cuda()\n",
    "    n = x.shape[0] # number of samples\n",
    "    k = x.shape[1] # dimension\n",
    "    t1 = -0.5*(x - mean)*(1/cov_diag)*(x-mean)\n",
    "    t1 = torch.sum(t1, dim=1)\n",
    "    t2 = 0.5*k*torch.log(2*torch.tensor([math.pi]).cuda()) + 0.5*torch.log(torch.prod(cov_diag,1)).cuda()\n",
    "    return t1 - t2\n",
    "    #return t1 - t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.0000, -0.0000, -0.0000],\n",
      "        [-0.5000, -0.5000, -0.0000]], device='cuda:0')\n",
      "tensor([[ 2.,  0.,  0.],\n",
      "        [ 1.,  1.,  0.]], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-4.7568, -3.7568], device='cuda:0')"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = torch.tensor([[0.,0.,0.],[0.,0.,0.]]).cuda()\n",
    "cov_diag = torch.tensor([[1.,1.,1.],[1.,1.,1.]]).cuda()\n",
    "x = torch.tensor([[2.,0.,0.],[1.,1.,0.]]).cuda()\n",
    "multivariate_normal_diagonal_logpdf(mean, cov_diag, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.7568]], device='cuda:0')"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = torch.tensor([0.,0.,0.]).cuda()\n",
    "cov = torch.eye(3).cuda()\n",
    "x = torch.tensor([1.,1.,0.]).cuda()\n",
    "multivariate_normal_logpdf(mean, cov, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.,  1.,  4.])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov_diag = torch.tensor([[1.,2.,1.],[1.,1.,1.],[4.,1.,1.]])\n",
    "torch.prod(cov_diag,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[1.,1.,1.],[2.,1.,0.]])\n",
    "y = torch.tensor([[2.,0.,0.],[1.,1.,1.]])\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 3])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = torch.tensor([[[0.,0.,0.]],[[0.,1.,0.]],[[0.,0.,0.]]])\n",
    "mean.shape\n",
    "cov = torch.tensor([[[1.,0.,0.],[0.,1.,0.],[0.,0.,1.]],[[1.,0.,0.],[0.,1.,0.],[0.,0.,1.]],[[1.,0.,0.],[0.,1.,0.],[0.,0.,1.]]])\n",
    "cov.shape\n",
    "x = torch.tensor([[[0., 2.,0.]],[[0., 0.,0.]],[[0., 0.,0.]]])\n",
    "mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 2])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = torch.tensor([[[0.,0.]],[[0.,1.]],[[0.,0.]]])\n",
    "mean.shape\n",
    "cov = torch.tensor([[[1.,0.],[0.,1.]],[[1.,0.],[0.,1.]],[[1.,0.],[0.,1.]]])\n",
    "cov.shape\n",
    "x = torch.tensor([[[0., 2.]],[[0., 0.]],[[0., 0.]]])\n",
    "mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.8379, -3.8379, -3.8379],\n",
       "        [-2.3379, -2.3379, -2.3379],\n",
       "        [-1.8379, -1.8379, -1.8379]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = MultivariateNormal(mean, cov)\n",
    "tt = m.log_prob(x)\n",
    "tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-2.7568])\n"
     ]
    }
   ],
   "source": [
    "mean = torch.tensor([[0., 0.,0.]])\n",
    "#mean = torch.tensor([[0.],[0.]])\n",
    "cov = torch.eye(3)\n",
    "x = torch.tensor([0., 0., 0.])\n",
    "m = MultivariateNormal(mean, cov)\n",
    "print(m.log_prob(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "class decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(decoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(z_dim, 400)\n",
    "        self.fc2 = nn.Linear(400, 784)\n",
    "    # single hidden layer\n",
    "    def forward(self, x):\n",
    "        #x = x.view(-1, 784)\n",
    "        h1 = F.relu(self.fc1(x))\n",
    "        return F.sigmoid(self.fc2(h1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "class q_z0(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(q_z0, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 300)\n",
    "        #self.fc2 = nn.Linear(300, 300)\n",
    "        self.fc31 = nn.Linear(300, z_dim)\n",
    "        self.fc32 = nn.Linear(300, z_dim)\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)\n",
    "        h1 = F.relu(self.fc1(x))\n",
    "        #h2 = F.relu(self.fc2(h1))\n",
    "        logvar = self.fc31(h1)\n",
    "        mu = self.fc32(h1)\n",
    "        return mu, logvar\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "class r_v(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(r_v, self).__init__()\n",
    "        self.fc1 = nn.Linear(z_dim + 784, 300)\n",
    "        self.fc21 = nn.Linear(300, z_dim)\n",
    "        self.fc22 = nn.Linear(300, z_dim)\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784 + z_dim)\n",
    "        h1 = F.softplus(self.fc1(x))\n",
    "        logvar = self.fc21(h1)\n",
    "        mu = self.fc22(h1)\n",
    "        return mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "class q_v(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(q_v, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 300)\n",
    "        # no need to output mu because the mean of momentum is default 0\n",
    "        self.fc21 = nn.Linear(300, z_dim)\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)\n",
    "        h1 = F.softplus(self.fc1(x))\n",
    "        logvar = self.fc21(h1)\n",
    "        return logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.9189, -0.9189])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = torch.zeros(2,1)\n",
    "cov = torch.eye(2)\n",
    "m = MultivariateNormal(mean, cov)\n",
    "x = torch.tensor([0.,0.]) \n",
    "m.log_prob(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = decoder().to(device)\n",
    "q_z0 = q_z0().to(device)\n",
    "r_v = r_v().to(device)\n",
    "q_v = q_v().to(device)\n",
    "log_mass_diag = torch.randn(z_dim, requires_grad=True)\n",
    "q_z0_mean = torch.randn(z_dim, requires_grad=True) \n",
    "q_z0_logvar = torch.randn(z_dim, requires_grad=True)\n",
    "#mass = torch.randn(z_dim, requires_grad=True)\n",
    "#mass = torch.eye(z_dim, requires_grad=True)\n",
    "#mass_cuda = mass.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_bound(decoder, q_z0_mean, q_z0_logvar, r_v, data, log_mass_diag, T):\n",
    "    batch_size = data.view(-1, 784).shape[0]\n",
    "    data = data.to(device)\n",
    "    \n",
    "    mu_z0 = q_z0_mean.repeat(batch_size,1).cuda()\n",
    "    logvar_z0 = q_z0_logvar.repeat(batch_size,1).cuda()\n",
    "    \n",
    "    #mu_z0, logvar_z0 = q_z0(data)\n",
    "    var_z0 = torch.exp(logvar_z0)\n",
    "    #print(mu_z0.shape)\n",
    "    #print(logvar_z0.shape)\n",
    "\n",
    "    # sample z0\n",
    "    z0 = reparameterize(mu_z0, logvar_z0)\n",
    "    #print(\"z0: \" + str(z0.shape))\n",
    "    #print(z0)\n",
    "\n",
    "    # get joint probaility p(x, z0)\n",
    "    log_prior_z0 = log_prior(z0)\n",
    "    #print(\"log_prior_z0: \" + str(log_prior_z0.shape))\n",
    "    decoder_output = decoder(z0)\n",
    "    #print(\"decoder_output: \" + str(decoder_output.shape))\n",
    "    log_likelihood = 0. - F.binary_cross_entropy(decoder_output, data.view(-1, 784).float(), size_average=False, reduce=False)\n",
    "    #print(\"log_likelihood: \" + str(log_likelihood.shape))\n",
    "    log_likelihood = torch.sum(log_likelihood, dim = 1)\n",
    "    #print(\"log_likelihood: \" + str(log_likelihood.shape))\n",
    "    log_joint = log_prior_z0 + log_likelihood\n",
    "    #print(\"log_joint: \" + str(log_joint.shape))\n",
    "\n",
    "    # get log q_z0\n",
    "    \"\"\"\n",
    "    print(\"~~~~~~~~~~~~~~~~~~\")\n",
    "    print(mu_z0.shape)\n",
    "    print(var_z0.shape)\n",
    "    print(z0.shape)\n",
    "    print(\"~~~~~~~~~~~~~~~~~~\")\n",
    "    log_q_z0 = torch.zeros(0).cuda()\n",
    "    for i in range(batch_size):\n",
    "        one_cov = torch.diag(var_z0[i])\n",
    "        #m = MultivariateNormal(mu_z0[i], one_cov)\n",
    "        #one_q_z0 = m.log_prob(z0[i]).view(1)\n",
    "        one_q_z0 = multivariate_normal_logpdf(mu_z0[i], one_cov, z0[i])\n",
    "        #print(\"one q z0: \" + str(one_q_z0))\n",
    "        log_q_z0 = torch.cat((log_q_z0,one_q_z0),0)\n",
    "    #print(\"log_q_z0: \" + str(log_q_z0.shape))\n",
    "    print(log_q_z0.shape)\n",
    "    \"\"\"\n",
    "    log_q_z0 = multivariate_normal_diagonal_logpdf(mu_z0, var_z0, z0)\n",
    "\n",
    "    # initial L for 128 samples\n",
    "    L = log_joint - log_q_z0.view(batch_size)\n",
    "    L = torch.sum(L)\n",
    "    #print(\"L \"+str(L))\n",
    "    #print(L.shape)\n",
    "\n",
    "    #print(\"====================================\")\n",
    "    for i in range(T):\n",
    "        \"\"\"\n",
    "         # sample v_t'(v1)\n",
    "        logvar_v1 = q_v(data)\n",
    "        var_v1 = torch.exp(logvar_v1)\n",
    "        #print(\"logvar_v1: \" + str(logvar_v1.shape))\n",
    "        mu_v1 = torch.zeros(logvar_v1.shape[0], logvar_v1.shape[1]).cuda()\n",
    "        v1 = reparameterize(mu_v1, logvar_v1)\n",
    "        #print(\"v1: \"+str(v1.shape))\n",
    "\n",
    "        # get q_v1\n",
    "        log_q_v1 = torch.zeros(0).cuda()\n",
    "        for i in range(batch_size):\n",
    "            one_cov = torch.diag(var_v1[i])\n",
    "            #m = MultivariateNormal(mu_v1[i], one_cov)\n",
    "            #one_q_v1 = m.log_prob(v1[i]).view(1)\n",
    "            one_q_v1 = multivariate_normal_logpdf(mu_v1[i], one_cov, v1[i])\n",
    "            log_q_v1 = torch.cat((log_q_v1,one_q_v1),0)\n",
    "        #print(\"log_q_v1: \"+str(log_q_v1.shape))\n",
    "        \"\"\"\n",
    "        # sample v1\n",
    "        mass_diag = torch.exp(log_mass_diag)\n",
    "        mass_matrix = torch.diag(mass_diag)\n",
    "        mass_matrix.cuda()\n",
    "        var_v1_matrix = torch.inverse(mass_matrix)\n",
    "        var_v1_diag = torch.diag(var_v1_matrix)\n",
    "        logvar_v1_diag = torch.log(var_v1_diag)\n",
    "        logvar_v1 = logvar_v1_diag.repeat(batch_size,1).cuda()\n",
    "        var_v1 = var_v1_diag.repeat(batch_size,1).cuda()\n",
    "        mu_v1 = torch.zeros(logvar_v1.shape[0], logvar_v1.shape[1]).cuda()\n",
    "        v1 = reparameterize(mu_v1, logvar_v1)\n",
    "        #print(v1)\n",
    "        \n",
    "        # get q_v1\n",
    "        \"\"\"\n",
    "        log_q_v1 = torch.zeros(0).cuda()\n",
    "        for i in range(batch_size):\n",
    "            one_cov = var_v1_matrix\n",
    "            #m = MultivariateNormal(mu_v1[i], one_cov)\n",
    "            #one_q_v1 = m.log_prob(v1[i]).view(1)\n",
    "            one_q_v1 = multivariate_normal_logpdf(mu_v1[i], one_cov, v1[i])\n",
    "            log_q_v1 = torch.cat((log_q_v1,one_q_v1),0)\n",
    "        #print(\"log_q_v1: \"+str(log_q_v1.shape))\n",
    "        \"\"\"\n",
    "        \n",
    "        log_q_v1 = multivariate_normal_diagonal_logpdf(mu_v1, var_v1 ,v1)\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        log_joint_t = torch.zeros(0).cuda() # list of all the joint\n",
    "        log_r_vt = torch.zeros(0).cuda()\n",
    "        alpha = torch.tensor([0.]).cuda() # lower bound for each batch (128 samples)\n",
    "        for j in range(batch_size):\n",
    "            def energy_function(z, cache):\n",
    "                z.retain_grad()\n",
    "                z = z.view(1, z.shape[0])\n",
    "                z = z.cuda()\n",
    "                one_log_prior = log_prior(z)\n",
    "                decoder_output = decoder(z)\n",
    "                one_log_likelihood = 0. - F.binary_cross_entropy(decoder_output, data.view(-1, 784)[j].float(), size_average=False, reduce=False)\n",
    "                #print(one_log_likelihood.shape)\n",
    "                one_log_likelihood = torch.sum(one_log_likelihood, dim = 1)\n",
    "                one_log_joint = one_log_prior + one_log_likelihood\n",
    "                return 0 - one_log_joint\n",
    "            sampler = IsotropicHmcSampler(energy_function, energy_grad=None, prng=None,\n",
    "                                          mom_resample_coeff=1., dtype=np.float64)\n",
    "            init = torch.zeros(z_dim).cuda()\n",
    "            \n",
    "            pos_samples, mom_samples, ratio = sampler.get_samples(init, 0.1, 3, 2, mass_matrix, mom = v1[j].view(z_dim))\n",
    "            #print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~`\")\n",
    "            #print(pos_samples[1].shape)\n",
    "\n",
    "            # get joint probaility p(x, zt)\n",
    "            zt = pos_samples[1].cuda()\n",
    "            vt = mom_samples[1].cuda()\n",
    "            zt = zt.view(1, zt.shape[0])\n",
    "            vt = vt.view(vt.shape[0])\n",
    "\n",
    "            # get joint probaility p(x, zt)\n",
    "            one_log_prior_zt = log_prior(zt)\n",
    "            #print(\"one_log_prior_zt: \" + str(one_log_prior_zt.shape))\n",
    "            one_decoder_output_t = decoder(zt)\n",
    "            #print(\"one_decoder_output_t: \" + str(one_decoder_output_t.shape))\n",
    "            one_log_likelihood_t = 0. - F.binary_cross_entropy(one_decoder_output_t, data.view(-1, 784)[j].float(), size_average=False, reduce=False)\n",
    "            one_log_likelihood_t = torch.sum(one_log_likelihood_t, dim = 1)\n",
    "            #print(\"one_log_likelihood_t: \" + str(one_log_likelihood_t.shape))\n",
    "            one_log_joint_t = one_log_prior_zt + one_log_likelihood_t\n",
    "            #print(\"one_log_joint_t: \" + str(one_log_joint_t.shape))\n",
    "            log_joint_t = torch.cat((log_joint_t, one_log_joint_t), 0)\n",
    "\n",
    "            # get r_vt\n",
    "            d = data.view(-1, 784)[j].view(1, 784)\n",
    "            one_new_data = torch.cat((d.float(), zt), 1) # append data with zt\n",
    "            one_mu_vt, one_logvar_vt = r_v(one_new_data)\n",
    "            one_var_vt = torch.exp(one_logvar_vt)\n",
    "            one_mu_vt = one_mu_vt.view(one_mu_vt.shape[1])\n",
    "            one_cov = torch.diag(one_var_vt.view(one_var_vt.shape[1]))\n",
    "            #m = MultivariateNormal(one_mu_vt, one_cov)\n",
    "            #one_log_r_vt = m.log_prob(vt).view(1)\n",
    "            one_log_r_vt = multivariate_normal_logpdf(one_mu_vt, one_cov, vt)\n",
    "            log_r_vt = torch.cat((log_r_vt, one_log_r_vt), 0)\n",
    "            \n",
    "\n",
    "            # get L for each sample\n",
    "            one_log_alpha = log_joint_t[j] + log_r_vt[j] - log_joint[j] - log_q_v1[j]\n",
    "            #print(\"one log alpha: \"+str(one_log_alpha))\n",
    "            #one_log_alpha = torch.log(one_alpha)\n",
    "            L = L + one_log_alpha\n",
    "            #alpha = alpha + one_alpha\n",
    "        #L = L + torch.log(alpha)\n",
    "\n",
    "    #print(\"~~~~~~~~~~~~~~~~~~~ new L \" + str(L) + \" ~~~~~~~~~~~~~~~~~~~\")\n",
    "    return L/batch_size    \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++ 0 ++++++++++\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1474: UserWarning: Using a target size (torch.Size([784])) that is different to the input size (torch.Size([1, 784])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-540.8179931640625\n",
      "++++++++++ 1 ++++++++++\n",
      "-549.0969848632812\n",
      "++++++++++ 2 ++++++++++\n",
      "-550.5850219726562\n",
      "++++++++++ 3 ++++++++++\n",
      "-535.8084106445312\n",
      "++++++++++ 4 ++++++++++\n",
      "-526.3399047851562\n",
      "++++++++++ 5 ++++++++++\n",
      "-523.1085815429688\n",
      "++++++++++ 6 ++++++++++\n",
      "-537.7744750976562\n",
      "++++++++++ 7 ++++++++++\n",
      "-526.813720703125\n",
      "++++++++++ 8 ++++++++++\n",
      "-533.3172607421875\n",
      "++++++++++ 9 ++++++++++\n",
      "-510.86700439453125\n",
      "++++++++++ 10 ++++++++++\n",
      "-512.7465209960938\n",
      "++++++++++ 11 ++++++++++\n",
      "-530.9485473632812\n",
      "++++++++++ 12 ++++++++++\n",
      "-507.992431640625\n",
      "++++++++++ 13 ++++++++++\n",
      "-498.8082275390625\n",
      "++++++++++ 14 ++++++++++\n",
      "-493.4671936035156\n",
      "++++++++++ 15 ++++++++++\n",
      "-492.0723571777344\n",
      "++++++++++ 16 ++++++++++\n",
      "-477.48822021484375\n",
      "++++++++++ 17 ++++++++++\n",
      "-490.0530700683594\n",
      "++++++++++ 18 ++++++++++\n",
      "-472.94879150390625\n",
      "++++++++++ 19 ++++++++++\n",
      "-496.95587158203125\n",
      "++++++++++ 20 ++++++++++\n",
      "-468.8138732910156\n",
      "++++++++++ 21 ++++++++++\n",
      "-461.9668884277344\n",
      "++++++++++ 22 ++++++++++\n",
      "-466.0077209472656\n",
      "++++++++++ 23 ++++++++++\n",
      "-462.1766662597656\n",
      "++++++++++ 24 ++++++++++\n",
      "-462.808349609375\n",
      "++++++++++ 25 ++++++++++\n",
      "-452.4923095703125\n",
      "++++++++++ 26 ++++++++++\n",
      "-463.9319763183594\n",
      "++++++++++ 27 ++++++++++\n",
      "-460.89178466796875\n",
      "++++++++++ 28 ++++++++++\n",
      "-435.68756103515625\n",
      "++++++++++ 29 ++++++++++\n",
      "-451.38775634765625\n",
      "++++++++++ 30 ++++++++++\n",
      "-445.6901550292969\n",
      "++++++++++ 31 ++++++++++\n"
     ]
    }
   ],
   "source": [
    "params1 = list(decoder.parameters())+list(q_z0.parameters())+list(r_v.parameters())\n",
    "optimizer1 = optim.Adam(params1, lr=0.0001)\n",
    "optimizer2 = optim.Adam([log_mass_diag, q_z0_mean, q_z0_logvar], lr=0.0001)\n",
    "nn.utils.clip_grad_norm_(q_z0.parameters(), 50)\n",
    "\n",
    "for i in range(len(result)):\n",
    "    print(\"++++++++++ \" + str(i) + \" ++++++++++\")\n",
    "    \n",
    "    data = result[i]\n",
    "    optimizer1.zero_grad()\n",
    "    optimizer2.zero_grad()\n",
    "    L = lower_bound(decoder, q_z0_mean, q_z0_logvar, r_v, data, log_mass_diag, 1)\n",
    "    loss = 0. - L\n",
    "    loss.backward()\n",
    "    #print('weight grad after backward')\n",
    "    #print(net.conv1.bias.grad)\n",
    "    #print(q_z0.fc1.weight.grad)\n",
    "    #print(q_z0.fc31.weight.grad)\n",
    "    #print(q_z0.fc32.weight.grad)\n",
    "    optimizer1.step()\n",
    "    optimizer2.step()\n",
    "    print(L.item())\n",
    "print(L.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++ 0 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1474: UserWarning: Using a target size (torch.Size([784])) that is different to the input size (torch.Size([1, 784])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-540.8672485351562\n",
      "++++++++++ 1 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-572.6387939453125\n",
      "++++++++++ 2 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-588.7979125976562\n",
      "++++++++++ 3 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-579.67236328125\n",
      "++++++++++ 4 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-559.671142578125\n",
      "++++++++++ 5 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-544.0812377929688\n",
      "++++++++++ 6 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-544.778076171875\n",
      "++++++++++ 7 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-516.0226440429688\n",
      "++++++++++ 8 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-505.8245544433594\n",
      "++++++++++ 9 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-497.9623107910156\n",
      "++++++++++ 10 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-487.72406005859375\n",
      "++++++++++ 11 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-463.9438781738281\n",
      "++++++++++ 12 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-466.0975341796875\n",
      "++++++++++ 13 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-452.3597717285156\n",
      "++++++++++ 14 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-450.99078369140625\n",
      "++++++++++ 15 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-429.5964050292969\n",
      "++++++++++ 16 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-434.8597412109375\n",
      "++++++++++ 17 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-417.3406677246094\n",
      "++++++++++ 18 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-407.9772033691406\n",
      "++++++++++ 19 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-411.21466064453125\n",
      "++++++++++ 20 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-403.7613525390625\n",
      "++++++++++ 21 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-404.00726318359375\n",
      "++++++++++ 22 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-399.34600830078125\n",
      "++++++++++ 23 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-390.32379150390625\n",
      "++++++++++ 24 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-378.6222229003906\n",
      "++++++++++ 25 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-375.39520263671875\n",
      "++++++++++ 26 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-372.48175048828125\n",
      "++++++++++ 27 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-361.93707275390625\n",
      "++++++++++ 28 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-359.9893493652344\n",
      "++++++++++ 29 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-373.8966979980469\n",
      "++++++++++ 30 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-359.6930236816406\n",
      "++++++++++ 31 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-350.148681640625\n",
      "++++++++++ 32 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-361.45147705078125\n",
      "++++++++++ 33 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-364.83154296875\n",
      "++++++++++ 34 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-356.56005859375\n",
      "++++++++++ 35 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-344.2277526855469\n",
      "++++++++++ 36 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-341.2362365722656\n",
      "++++++++++ 37 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-362.663330078125\n",
      "++++++++++ 38 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-345.8728332519531\n",
      "++++++++++ 39 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-363.71917724609375\n",
      "++++++++++ 40 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-352.9364318847656\n",
      "++++++++++ 41 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-353.8746337890625\n",
      "++++++++++ 42 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-342.87945556640625\n",
      "++++++++++ 43 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-326.8343811035156\n",
      "++++++++++ 44 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-360.9006042480469\n",
      "++++++++++ 45 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-344.5437927246094\n",
      "++++++++++ 46 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-338.8890686035156\n",
      "++++++++++ 47 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n",
      "-325.91522216796875\n",
      "++++++++++ 48 ++++++++++\n",
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-219-1e33a8fd0192>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0moptimizer1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0moptimizer2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mL\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlower_bound\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mq_z0_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mq_z0_logvar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr_v\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_mass_diag\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mL\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-218-000e7370f612>\u001b[0m in \u001b[0;36mlower_bound\u001b[1;34m(decoder, q_z0_mean, q_z0_logvar, r_v, data, log_mass_diag, T)\u001b[0m\n\u001b[0;32m    114\u001b[0m             \u001b[0minit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m             \u001b[0mpos_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmom_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mratio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msampler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmass_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m             \u001b[1;31m#print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~`\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m             \u001b[1;31m#print(pos_samples[1].shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Cambridge\\Project\\MHMC-for-VAE\\hmc_pytorch\\hmc_base_pytorch.py\u001b[0m in \u001b[0;36mget_samples\u001b[1;34m(self, pos, dt, n_step_per_sample, n_sample, mass, mom)\u001b[0m\n\u001b[0;32m    112\u001b[0m             \u001b[1;31m# Metropolis-Hastings accept step on proposed update\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             if (proposal_successful and self.prng.uniform() <\n\u001b[1;32m--> 114\u001b[1;33m                     torch.exp(hamiltonian_c - hamiltonian_p).item()):\n\u001b[0m\u001b[0;32m    115\u001b[0m                 \u001b[1;31m# accept move\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m                 \u001b[0mpos_samples\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmom_samples\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcache\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpos_p\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmom_p\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcache_p\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "params1 = list(decoder.parameters())+list(q_z0.parameters())+list(r_v.parameters())\n",
    "optimizer1 = optim.Adam(params1, lr=0.0003)\n",
    "optimizer2 = optim.Adam([log_mass_diag, q_z0_mean, q_z0_logvar], lr=0.0003)\n",
    "nn.utils.clip_grad_norm_(q_z0.parameters(), 50)\n",
    "for batch_idx, (data, _) in enumerate(train_loader):\n",
    "    print(\"++++++++++ \" + str(batch_idx) + \" ++++++++++\")\n",
    "    \n",
    "    optimizer1.zero_grad()\n",
    "    optimizer2.zero_grad()\n",
    "    L = lower_bound(decoder, q_z0_mean, q_z0_logvar, r_v, data, log_mass_diag, 1)\n",
    "    loss = 0. - L\n",
    "    loss.backward()\n",
    "    #print('weight grad after backward')\n",
    "    #print(net.conv1.bias.grad)\n",
    "    #print(q_z0.fc1.weight.grad)\n",
    "    #print(q_z0.fc31.weight.grad)\n",
    "    #print(q_z0.fc32.weight.grad)\n",
    "    optimizer1.step()\n",
    "    optimizer2.step()\n",
    "    print(L.item())\n",
    "print(L.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "params argument given to the optimizer should be an iterable of Tensors or dicts, but got torch.FloatTensor",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-143b7071f5f2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m#x = Variable(torch.randn(5))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\optim\\sgd.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, params, lr, momentum, dampening, weight_decay, nesterov)\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnesterov\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmomentum\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mdampening\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Nesterov momentum requires a momentum and zero dampening\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSGD\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setstate__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\optim\\optimizer.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, params, defaults)\u001b[0m\n\u001b[0;32m     29\u001b[0m             raise TypeError(\"params argument given to the optimizer should be \"\n\u001b[0;32m     30\u001b[0m                             \u001b[1;34m\"an iterable of Tensors or dicts, but got \"\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m                             torch.typename(params))\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: params argument given to the optimizer should be an iterable of Tensors or dicts, but got torch.FloatTensor"
     ]
    }
   ],
   "source": [
    "#params = mass_diag\n",
    "\n",
    "\n",
    "#optimizer = optim.Adam(params, lr=1e-3)\n",
    "\n",
    "w = torch.randn([3,5], requires_grad=True)\n",
    "b = torch.randn(3, requires_grad=True)\n",
    "#x = Variable(torch.randn(5))\n",
    "\n",
    "optimizer = optim.SGD([w], lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([400, 20])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(decoder.parameters())\n",
    "params[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(decoder.parameters())[0]\n",
    "#list(mass_diag)[0]\n",
    "mass_diag.is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 784])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt = torch.ones(1, 784).cuda()\n",
    "print(tt.shape)\n",
    "torch.sum(tt, dim=1)\n",
    "tt.is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[0.1, 0.1],[0.1,0.1],[0.1,0.1]])\n",
    "y = torch.tensor([[0.5, 0.5],[0.5,0.5],[1.,1.]])\n",
    "L = F.binary_cross_entropy(y, x, size_average=False, reduce=False)\n",
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Lapack Error getrf : U(2,2) is 0, U is singular at c:\\programdata\\miniconda3\\conda-bld\\pytorch_1524546354046\\work\\aten\\src\\th\\generic/THTensorLapack.c:514",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-dee977365fee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: Lapack Error getrf : U(2,2) is 0, U is singular at c:\\programdata\\miniconda3\\conda-bld\\pytorch_1524546354046\\work\\aten\\src\\th\\generic/THTensorLapack.c:514"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[0.1, 0.1],[0.1,0.1]])\n",
    "torch.inverse(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  1.3863,   1.3863,  49.7358])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(L, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  0,  0],\n",
       "        [ 0,  2,  0],\n",
       "        [ 0,  0,  3]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.diag(torch.tensor([1, 2, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.0050])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.normal(torch.tensor([0.]),torch.tensor([1.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  0.],\n",
       "        [ 0.,  1.]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eye(2, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3646,  0.7910,  0.5176]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x.view(1, 3)\n",
    "y.view(1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "for i in range(500):\n",
    "    x.append(reparameterize(torch.tensor([0.]), torch.tensor([1.])).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a17b3eba90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(x)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "invalid argument 1: A should be 2 dimensional at c:\\programdata\\miniconda3\\conda-bld\\pytorch_1524546354046\\work\\aten\\src\\th\\generic/THTensorLapack.c:492",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-2e0303639b8f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: invalid argument 1: A should be 2 dimensional at c:\\programdata\\miniconda3\\conda-bld\\pytorch_1524546354046\\work\\aten\\src\\th\\generic/THTensorLapack.c:492"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1,0,0],[0,0.5,0],[0,0,0.4]])\n",
    "y = torch.diag(x)\n",
    "torch.inverse(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000,  0.0000, -0.0000],\n",
       "        [ 0.0000,  2.0000, -0.0000],\n",
       "        [ 0.0000,  0.0000,  2.5000]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.inverse(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.5000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.4000]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.0000,  0.5000,  0.4000])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.diag(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
