{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('F:\\Cambridge\\Project\\MHMC-for-VAE\\change_of_variable')\n",
    "sys.path.append('F:\\Cambridge\\Project\\MHMC-for-VAE\\hmc_pytorch')\n",
    "from change_of_variable_pytorch import * \n",
    "from hmc_base_pytorch import *\n",
    "from hmc_unconstrained_pytorch import *\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "from torch.distributions.normal import Normal\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch.utils.data\n",
    "from torch import optim\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "import time\n",
    "import torchvision\n",
    "\n",
    "\n",
    "cuda = True\n",
    "batch_size = 64\n",
    "epochs = 10\n",
    "seed = 1\n",
    "z_dim = 20\n",
    "\n",
    "# Data preparation\n",
    "torch.manual_seed(seed)\n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if cuda else {}\n",
    "\n",
    "train_data = datasets.MNIST('../data', train=True, download=True, transform=transforms.ToTensor())\n",
    "test_data = datasets.MNIST('../data', train=False, transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_data,\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_data,\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "def binarization(data):\n",
    "    s = np.random.uniform(size = data.shape)\n",
    "    out = np.array(s<data).astype(float)\n",
    "    return out\n",
    "\n",
    "result = []\n",
    "for batch_idx, (data, _) in enumerate(train_loader):\n",
    "    data = data.view(-1, 784).numpy()\n",
    "    bi_data = binarization(data)\n",
    "    d = torch.from_numpy(bi_data)\n",
    "    result.append(d)\n",
    "    \n",
    "result_2d = []\n",
    "for batch_idx, (data, _) in enumerate(train_loader):\n",
    "    #data = data.view(-1, 28, 28).numpy()\n",
    "    #print(\"data: \"+str(data.shape))\n",
    "    bi_data = binarization(data)\n",
    "    d = torch.from_numpy(bi_data)\n",
    "    result_2d.append(d)\n",
    "    \n",
    "result_test = []\n",
    "for batch_idx, (data, _) in enumerate(test_loader):\n",
    "    data = data.view(-1, 784).numpy()\n",
    "    bi_data = binarization(data)\n",
    "    d = torch.from_numpy(bi_data)\n",
    "    result_test.append(d)\n",
    "\n",
    "############################################################\n",
    "def reparameterize(mu, logvar):\n",
    "    std = torch.exp(0.5*logvar)\n",
    "    eps = torch.randn_like(std)\n",
    "    #return eps.mul(std).add_(mu)\n",
    "    return eps*std+mu\n",
    "\n",
    "def log_prior(z):\n",
    "    dim = z.shape[1]\n",
    "    mean = torch.zeros(dim).cuda()\n",
    "    cov = torch.eye(dim).cuda()\n",
    "    m = MultivariateNormal(mean, cov)\n",
    "    m.requires_grad=True\n",
    "    return m.log_prob(z)\n",
    "\n",
    "def multivariate_normal_diagonal_logpdf(mean, cov_diag, x):\n",
    "    n = x.shape[0] # number of samples\n",
    "    k = x.shape[1] # dimension\n",
    "    t1 = -0.5*(x - mean)*(1/cov_diag)*(x-mean)\n",
    "    t1 = torch.sum(t1, dim=1)\n",
    "    t2 = torch.ones(n).cuda()*0.5*k*torch.log(torch.tensor([2*math.pi]).cuda()) + 0.5*torch.sum(torch.log(cov_diag),dim=1)\n",
    "    return t1 - t2\n",
    "############################################################\n",
    "\"\"\"\n",
    "class decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(decoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(z_dim, 400)\n",
    "        self.fc2 = nn.Linear(400, 784)\n",
    "    # single hidden layer\n",
    "    def forward(self, x):\n",
    "        #x = x.view(-1, 784)\n",
    "        h1 = F.relu(self.fc1(x))\n",
    "        return F.sigmoid(self.fc2(h1))\n",
    "\"\"\"\n",
    "class decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(decoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(z_dim, 300)\n",
    "        self.fc2 = nn.Linear(300, 512)\n",
    "        self.deconv1 = nn.ConvTranspose2d(32, 32, 5, stride = 2, padding=2)# padding = 2)\n",
    "        self.deconv2 = nn.ConvTranspose2d(32, 16, 5, stride = 2, padding=2, output_padding=1)#padding = 2, output_padding=1)\n",
    "        self.deconv3 = nn.ConvTranspose2d(16, 1, 5, stride = 2, padding=2, output_padding=1)#padding = 2, output_padding=0)\n",
    "    # single hidden layer\n",
    "    def forward(self, x):\n",
    "        #x = x.view(-1, 784)\n",
    "        #print(\"x: \"+str(x.shape))\n",
    "        h1 = F.softplus(self.fc1(x))\n",
    "        print(\"h1: \"+str(h1.shape))\n",
    "        h2 = F.softplus(self.fc2(h1))\n",
    "        print(\"h2: \"+str(h2.shape))\n",
    "        h2 = h2.view(-1, 32, 4, 4)\n",
    "        print(\"h2: \"+str(h2.shape))\n",
    "        h3 = F.softplus(self.deconv1(h2))\n",
    "        print(\"h3: \"+str(h3.shape))\n",
    "        h4 = F.softplus(self.deconv2(h3))\n",
    "        print(\"h4: \"+str(h4.shape))\n",
    "        h5 = self.deconv3(h4)\n",
    "        print(\"h5: \"+str(h5.shape))\n",
    "        plt.imshow(h5[0].cpu().detach().numpy().reshape(27,27), cmap='gray')\n",
    "        plt.show()\n",
    "        return F.sigmoid(h5.view(-1, 784))    \n",
    "class q_z0(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(q_z0, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, 5, stride = 2, padding = 2 ) # output 12.5\n",
    "        self.conv2 = nn.Conv2d(16, 32, 5, stride = 2, padding = 2) # \n",
    "        self.conv3 = nn.Conv2d(32, 32, 5, stride = 2, padding = 2)\n",
    "        self.fc1 = nn.Linear(512, 300)\n",
    "        self.fc21 = nn.Linear(300, z_dim)\n",
    "        self.fc22 = nn.Linear(300, z_dim)\n",
    "    def forward(self, x):\n",
    "        #print(\"x: \"+str(x.shape))\n",
    "        h1 = F.softplus(self.conv1(x))\n",
    "        #print(h1.shape)\n",
    "        h2 = F.softplus(self.conv2(h1))\n",
    "        #print(h2.shape)\n",
    "        h3 = F.softplus(self.conv3(h2))\n",
    "        #print(h3.shape)\n",
    "        h3 = h3.view(-1, 32*4*4)\n",
    "        h4 = F.softplus(self.fc1(h3))\n",
    "        mu = F.softplus(self.fc21(h4))\n",
    "        logvar = F.softplus(self.fc22(h4))\n",
    "        return mu, logvar\n",
    "class r_v(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(r_v, self).__init__()\n",
    "        self.fc1 = nn.Linear(z_dim + 784, 300)\n",
    "        self.fc21 = nn.Linear(300, z_dim)\n",
    "        self.fc22 = nn.Linear(300, z_dim)\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784 + z_dim)\n",
    "        h1 = F.softplus(self.fc1(x))\n",
    "        logvar = self.fc21(h1)\n",
    "        mu = self.fc22(h1)\n",
    "        return mu, logvar\n",
    "\n",
    "class q_v(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(q_v, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 300)\n",
    "        # no need to output mu because the mean of momentum is default 0\n",
    "        self.fc21 = nn.Linear(300, z_dim)\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)\n",
    "        h1 = F.softplus(self.fc1(x))\n",
    "        logvar = self.fc21(h1)\n",
    "        return logvar\n",
    "############################################################\n",
    "decoder = decoder().to(device)\n",
    "q_z0 = q_z0().to(device)\n",
    "r_v = r_v().to(device)\n",
    "q_v = q_v().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 784])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ELBO(data, decoder, q_z0, r_v, q_v, log_step, T):#q_z0_mean, q_z0_logvar):\n",
    "    \n",
    "    #file1 = open(\"q_z0_mean\"+str(epoch)+\".txt\",\"w\")\n",
    "    #file1 = open(\"q_z0_var\"+str(epoch)+\".txt\",\"w\")\n",
    "    #file1 = open(\"z0\"+str(epoch)+\".txt\",\"w\")\n",
    "    batch_size = data.view(-1, 784).shape[0]\n",
    "    data = data.to(device)\n",
    "    \n",
    "    q_z0_mean, q_z0_logvar = q_z0(data.view(-1, 1, 28, 28))\n",
    "    # sample z0\n",
    "    z0 = reparameterize(q_z0_mean, q_z0_logvar)\n",
    "    \n",
    "    # compute q(z0|x)\n",
    "    var_z0 = torch.exp(q_z0_logvar)\n",
    "    log_q_z0 = multivariate_normal_diagonal_logpdf(q_z0_mean, var_z0, z0)\n",
    "    \n",
    "    #print(\"q z0 mean: \"+str(q_z0_mean))\n",
    "    #print(\"q z0 var: \"+str(var_z0))\n",
    "    #print(\"z0: \"+str(z0))\n",
    "    #print(\"q(z0|x): \"+str(log_q_z0))\n",
    "    #print(\"np q(z0|x): \"+str(np_log_q_z0))\n",
    "    \n",
    "    # compute prior\n",
    "    log_prior_z0 = log_prior(z0)\n",
    "    \n",
    "    \n",
    "    # compute joint\n",
    "    decoder_output = decoder(z0)\n",
    "    #print(\"decoder: \"+str(decoder_output))\n",
    "    log_likelihood = 0. - F.binary_cross_entropy(decoder_output, data.view(-1, 784).float(), size_average=False, reduce=False)\n",
    "    #print(\"ll: \"+str(log_likelihood))\n",
    "    log_likelihood = torch.sum(log_likelihood, dim = 1)\n",
    "    log_joint = log_prior_z0 + log_likelihood\n",
    "    \n",
    "    \n",
    "    # initial L\n",
    "    #L = log_joint - log_q_z0\n",
    "    L = -log_q_z0\n",
    "    #print(\"initial L: \"+str(L))\n",
    "    #print(\"log likelihood 0: \"+str(torch.mean(log_likelihood)))\n",
    "    \n",
    "    for i in range(T):\n",
    "        # sample v1\n",
    "        \n",
    "        logvar_v1 = q_v(data)\n",
    "        \n",
    "        #logvar_v1 = torch.zeros([batch_size, z_dim], requires_grad = True).cuda()\n",
    "        var_v1 = torch.exp(logvar_v1)\n",
    "        mu_v1 = torch.zeros([logvar_v1.shape[0], logvar_v1.shape[1]],requires_grad = True).cuda()\n",
    "        v1 = reparameterize(mu_v1, logvar_v1)\n",
    "        #print(\"v1: \"+str(v1.shape))\n",
    "        \n",
    "        # compute q(v1|x) \n",
    "        log_q_v1 = multivariate_normal_diagonal_logpdf(mu_v1, var_v1 ,v1)\n",
    "        #print(\"log_q_v1: \"+str(log_q_v1.shape))\n",
    "        #print(\"var_v1: \"+str(var_v1))\n",
    "        \n",
    "        mass_diag = var_v1\n",
    "        #print(\"mass_diag: \"+str(mass_diag))\n",
    "        \n",
    "        def energy_function(z, cache):\n",
    "            z = z.view(batch_size, z_dim)\n",
    "            z_cuda = z.cuda()\n",
    "            all_log_prior = log_prior(z_cuda)\n",
    "            #print(\"all prior: \"+str(all_log_prior.shape))\n",
    "            all_log_prior = torch.sum(all_log_prior)\n",
    "            #print(all_log_prior.shape)\n",
    "            decoder_output = decoder(z_cuda)\n",
    "\n",
    "            all_log_likelihood = 0. - F.binary_cross_entropy(decoder_output, data.view(-1, 784).float(), size_average=False)\n",
    "            #print(\"one_log_likelihood: \"+str(one_log_likelihood.shape))\n",
    "            all_log_joint = all_log_prior + all_log_likelihood\n",
    "            return 0 - all_log_joint\n",
    "        \n",
    "        \n",
    "        init = z0.view(batch_size*z_dim)\n",
    "        mass_diag = mass_diag.view(mass_diag.shape[0]*mass_diag.shape[1])\n",
    "        mass_matrix = torch.diag(mass_diag)\n",
    "        mom = v1.view(v1.shape[0]*v1.shape[1])\n",
    "        step = torch.exp(log_step)\n",
    "        #print(\"init: \"+str(init.shape))\n",
    "        #print(\"mass: \"+str(mass_matrix.shape))\n",
    "        \n",
    "        # clip step size\n",
    "        low = 0.0005\n",
    "        high = 0.5\n",
    "        torch.clamp(step, min=low, max=high)\n",
    "        step = step.repeat(1, batch_size)\n",
    "        step = step.view(step.shape[1])\n",
    "        step_cuda = step.cuda()\n",
    "        #print(\"log step: \"+str(log_step))\n",
    "        #print(\"step: \"+str(step_cuda))\n",
    "        \n",
    "        sampler = IsotropicHmcSampler(energy_function, energy_grad=None, prng=None, mom_resample_coeff=0., dtype=np.float64)\n",
    "        #pos_samples, mom_samples, ratio = sampler.get_samples(init, 0.0001, 5, 2, mass_matrix, mom = mom)\n",
    "        pos_samples, mom_samples, ratio = sampler.get_samples(init, step_cuda, 5, 2, mass_matrix, mom = mom)\n",
    "        \n",
    "        zt = pos_samples[1].cuda()\n",
    "        vt = mom_samples[1].cuda()\n",
    "        \n",
    "        zt = zt.view(batch_size, z_dim)\n",
    "        vt = vt.view(batch_size, z_dim)\n",
    "\n",
    "        # get joint probaility p(x, zt)\n",
    "        log_prior_zt = log_prior(zt)\n",
    "        decoder_output_t = decoder(zt)\n",
    "        #print(\"log prior: \" + str(log_prior_zt.shape))\n",
    "        #print(\"decoder: \" + str(decoder_output_t.shape))\n",
    "\n",
    "        log_likelihood_t = 0. - F.binary_cross_entropy(decoder_output_t, data.view(-1, 784).float(), size_average=False, reduce=False)\n",
    "        log_likelihood_t = torch.sum(log_likelihood_t, dim = 1)\n",
    "        #print(\"log ll: \" + str(log_likelihood_t.shape))\n",
    "        \n",
    "        log_joint_t = log_prior_zt + log_likelihood_t\n",
    "        #print(\"log joint t: \" + str(log_joint_t.shape))\n",
    "        \n",
    "        # get r(vt|x,zt)\n",
    "        d = data.view(-1, 784)\n",
    "        #print(d.shape)\n",
    "        new_data = torch.cat((d.float(), zt), 1) # append data with zt\n",
    "        #print(\"new data: \"+str(one_new_data.shape))\n",
    "\n",
    "        mu_vt, logvar_vt = r_v(new_data)\n",
    "        var_vt = torch.exp(logvar_vt)\n",
    "        #print(\"var_vt: \"+str(var_vt.shape))\n",
    "\n",
    "        log_r_vt = multivariate_normal_diagonal_logpdf(mu_vt, var_vt, vt)\n",
    "        \"\"\"\n",
    "        print(\"log prior t: \"+str(torch.mean(log_prior_zt)))\n",
    "        print(\"log likelihood t: \"+str(torch.mean(log_likelihood_t)))\n",
    "        print(\"joint t: \"+str(torch.mean(log_joint_t)))\n",
    "        print(\"reverse: \"+str(torch.mean(log_r_vt)))\n",
    "        #print(log_joint[j])\n",
    "        print(\"forward: \"+str(torch.mean(log_q_v1)))\n",
    "        print(\"q(z0|x): \"+str(torch.mean(log_q_z0)))\n",
    "        print(\"========================================`\")\n",
    "        \"\"\"\n",
    "        #file1 = open(\"q_z0_mean\"+str(epoch)+\".txt\",\"w\")\n",
    "        #file2 = open(\"q_z0_var\"+str(epoch)+\".txt\",\"w\")\n",
    "        #file3 = open(\"z0\"+str(epoch)+\".txt\",\"w\")\n",
    "        \n",
    "        # get L for each sample\n",
    "        #one_log_alpha = one_log_joint_t + one_log_r_vt - log_joint[j] - log_q_v1[j]\n",
    "        log_alpha = log_joint_t + log_r_vt - log_q_v1\n",
    "        #one_log_alpha = log_joint[j] #+ one_log_r_vt - log_q_v1[j]\n",
    "\n",
    "        L = L + log_alpha\n",
    "        #print(\"L: \"+str(L.shape))\n",
    "    \n",
    "    \n",
    "    return torch.mean(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "++++++++++ Epoch: 1 batch: 0 ++++++++++\n",
      "h1: torch.Size([64, 300])\n",
      "h2: torch.Size([64, 512])\n",
      "h2: torch.Size([64, 32, 4, 4])\n",
      "h3: torch.Size([64, 32, 7, 7])\n",
      "h4: torch.Size([64, 16, 14, 14])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "invalid argument 15: output padding must be smaller than either stride or dilation, but got adjH: 2 adjW: 2 dH: 2 dW: 2 dilationH: 1 dilationW: 1 at c:\\programdata\\miniconda3\\conda-bld\\pytorch_1524546354046\\work\\aten\\src\\thcunn\\generic/SpatialFullDilatedConvolution.cu:21",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-4c6260608508>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0moptimizer1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0moptimizer2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mELBO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mq_z0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr_v\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mq_v\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#_mean_cuda, q_z0_logvar_cuda)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ELBO: \"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-23-be87f3d66c9e>\u001b[0m in \u001b[0;36mELBO\u001b[1;34m(data, decoder, q_z0, r_v, q_v, log_step, T)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;31m# compute joint\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[0mdecoder_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m     \u001b[1;31m#print(\"decoder: \"+str(decoder_output))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[0mlog_likelihood\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecoder_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m784\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 491\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    492\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-21-63e8c3637d99>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    127\u001b[0m         \u001b[0mh4\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftplus\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeconv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"h4: \"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh4\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 129\u001b[1;33m         \u001b[0mh5\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeconv3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    130\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"h5: \"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh5\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh5\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m27\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m27\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'gray'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 491\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    492\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, output_size)\u001b[0m\n\u001b[0;32m    688\u001b[0m         return F.conv_transpose2d(\n\u001b[0;32m    689\u001b[0m             \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 690\u001b[1;33m             output_padding, self.groups, self.dilation)\n\u001b[0m\u001b[0;32m    691\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    692\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: invalid argument 15: output padding must be smaller than either stride or dilation, but got adjH: 2 adjW: 2 dH: 2 dW: 2 dilationH: 1 dilationW: 1 at c:\\programdata\\miniconda3\\conda-bld\\pytorch_1524546354046\\work\\aten\\src\\thcunn\\generic/SpatialFullDilatedConvolution.cu:21"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "z_dim = 20\n",
    "\n",
    "params1 = list(decoder.parameters())+list(q_z0.parameters())+list(r_v.parameters())+list(q_v.parameters())\n",
    "optimizer1 = optim.Adam(params1, lr=0.0001)#, weight_decay=1e-4)\n",
    "#optimizer1 = optim.Adam([q_z0_mean], lr=0.005)\n",
    "#log_step_raw = torch.ones(z_dim, requires_grad=True)\n",
    "#log_step = -3.0*log_step_raw\n",
    "log_step=torch.tensor([-3.,-3.,-3.,-3.,-3.,-3.,-3.,-3.,-3.,-3.,-3.,-3.,-3.,-3.,-3.,-3.,-3.,-3.,-3.,-3.], requires_grad=True)\n",
    "optimizer2 = optim.Adam([log_step], lr=0.001)\n",
    "\n",
    "\n",
    "for epoch in range(20):\n",
    "    print(\"Epoch: \"+str(epoch+1))\n",
    "    file = open(\"result11_\"+str(epoch)+\".txt\",\"w\")\n",
    "    file_test = open(\"result11_test_\"+str(epoch)+\".txt\",\"w\")\n",
    "    for i in range(len(result)):\n",
    "        print(\"++++++++++\"+\" Epoch: \"+str(epoch+1)+\" batch: \" + str(i) + \" ++++++++++\")\n",
    "        data = result[i].float()\n",
    "        #data_2d = result_2d[i].float()\n",
    "        optimizer1.zero_grad()\n",
    "        optimizer2.zero_grad()\n",
    "        loss = 0. - ELBO(data, decoder, q_z0, r_v, q_v, log_step, 1)#_mean_cuda, q_z0_logvar_cuda)\n",
    "        print(\"ELBO: \"+str(0-loss.item()))\n",
    "        loss.backward()\n",
    "        #nn.utils.clip_grad_norm_(q_z0.parameters(), 1)\n",
    "        #print(q_z0.fc1.weight.grad)\n",
    "        #print(q_z0.fc31.weight.grad)\n",
    "        #print(q_z0.fc32.weight.grad)\n",
    "        optimizer1.step()\n",
    "        optimizer2.step()\n",
    "        file.write(str(0.-loss.item())+\"\\n\")\n",
    "    file.close()\n",
    "    for i in range(len(result_test)):\n",
    "        print(\"++++++++++ test batch: \" + str(i) + \" ++++++++++\")\n",
    "        data = result_test[i].float()\n",
    "        loss = 0. - ELBO(data, decoder, q_z0, r_v, q_v, log_step, 1)\n",
    "        print(\"ELBO: \"+str(0-loss.item()))\n",
    "        file_test.write(str(0.-loss.item())+\"\\n\")\n",
    "        \n",
    "    file_test.close()\n",
    "    \n",
    "    sample = torch.randn(64, 20).to(device)\n",
    "    sample = decoder(sample).cpu()\n",
    "    save_image(sample.view(64, 1, 28, 28), 'sample11_' + str(epoch) + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = torch.tensor([1., 2.])\n",
    "tmp = torch.tensor([2., 4.])\n",
    "x = dt*tmp\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.,  0.,  0.]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[1., 2.],[0., 0.]]).view(-1, 4)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.],\n",
       "        [ 0.,  0.]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.view(2,2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
