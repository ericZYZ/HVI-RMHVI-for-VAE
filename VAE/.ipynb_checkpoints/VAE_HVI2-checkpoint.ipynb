{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('F:\\Cambridge\\Project\\MHMC-for-VAE\\change_of_variable')\n",
    "sys.path.append('F:\\Cambridge\\Project\\MHMC-for-VAE\\hmc_pytorch')\n",
    "from change_of_variable_pytorch import * \n",
    "from hmc_base_pytorch import *\n",
    "from hmc_unconstrained_pytorch import *\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "from torch.distributions.normal import Normal\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch.utils.data\n",
    "from torch import optim\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.141592653589793"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = True\n",
    "batch_size = 128\n",
    "epochs = 10\n",
    "seed = 1\n",
    "log_interval = 10\n",
    "z_dim = 20\n",
    "\n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if cuda else {}\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True,\n",
    "                   transform=transforms.ToTensor()),\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, transform=transforms.ToTensor()),\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reparameterize(mu, logvar):\n",
    "    std = torch.exp(0.5*logvar)\n",
    "    eps = torch.randn_like(std)\n",
    "    return eps.mul(std).add_(mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_prior(z):\n",
    "    dim = z.shape[1]\n",
    "    mean = torch.zeros(dim).cuda()\n",
    "    cov = torch.eye(dim).cuda()\n",
    "    m = MultivariateNormal(mean, cov)\n",
    "    m.requires_grad=True\n",
    "    return m.log_prob(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multivariate_normal_logpdf(mean, cov, x):\n",
    "    mean = mean.cuda()\n",
    "    cov = cov.cuda()\n",
    "    k = x.shape[0]\n",
    "    #cov = cov + (1e-6*torch.eye(k)).cuda()\n",
    "    t1 = -0.5*(x - mean).view(1, k)@torch.inverse(cov)@(x - mean).view(k, 1)\n",
    "    #t21 = 0.5*k*torch.log(2*torch.tensor([math.pi]).cuda())\n",
    "    #t22 = 0.5*torch.log(torch.det(cov))\n",
    "    #t2 = t21 + t22\n",
    "    t2 = 0.5*k*torch.log(2*torch.tensor([math.pi]).cuda()) + 0.5*torch.log(torch.det(cov))\n",
    "    return t1 - t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  0.,  0.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.],\n",
       "        [ 0.,  0.,  1.,  0.],\n",
       "        [ 0.,  0.,  0.,  1.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eye(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.3379]], device='cuda:0')\n",
      "--- 0.009974956512451172 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "mean = torch.tensor([0., 0.]).cuda()\n",
    "cov = torch.eye(2).cuda()\n",
    "x = torch.tensor([0., 1.]).cuda()\n",
    "print(multivariate_normal_logpdf(mean, cov, x))\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-2.3379, device='cuda:0')\n",
      "--- 0.013963699340820312 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "mean = torch.tensor([0., 0.]).cuda()\n",
    "cov = torch.eye(2).cuda()\n",
    "x = torch.tensor([0., 1.]).cuda()\n",
    "m = MultivariateNormal(mean, cov)\n",
    "print(m.log_prob(x))\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-2.3379, device='cuda:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = MultivariateNormal(mean, cov)\n",
    "m.log_prob(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2])\n"
     ]
    }
   ],
   "source": [
    "z = torch.tensor([[1.,1.],[2.,2.],[3.,3.]])\n",
    "print(z.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(decoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(z_dim, 400)\n",
    "        self.fc2 = nn.Linear(400, 784)\n",
    "    # single hidden layer\n",
    "    def forward(self, x):\n",
    "        #x = x.view(-1, 784)\n",
    "        h1 = F.relu(self.fc1(x))\n",
    "        return F.sigmoid(self.fc2(h1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class q_z0(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(q_z0, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 300)\n",
    "        self.fc2 = nn.Linear(300, 300)\n",
    "        self.fc31 = nn.Linear(300, z_dim)\n",
    "        self.fc32 = nn.Linear(300, z_dim)\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)\n",
    "        h1 = F.softplus(self.fc1(x))\n",
    "        h2 = F.softplus(self.fc2(h1))\n",
    "        logvar = self.fc31(h2)\n",
    "        mu = self.fc32(h2)\n",
    "        return mu, logvar\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class r_v(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(r_v, self).__init__()\n",
    "        self.fc1 = nn.Linear(z_dim + 784, 300)\n",
    "        self.fc21 = nn.Linear(300, z_dim)\n",
    "        self.fc22 = nn.Linear(300, z_dim)\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784 + z_dim)\n",
    "        h1 = F.softplus(self.fc1(x))\n",
    "        logvar = self.fc21(h1)\n",
    "        mu = self.fc22(h1)\n",
    "        return mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class q_v(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(q_v, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 300)\n",
    "        # no need to output mu because the mean of momentum is default 0\n",
    "        self.fc21 = nn.Linear(300, z_dim)\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)\n",
    "        h1 = F.softplus(self.fc1(x))\n",
    "        logvar = self.fc21(h1)\n",
    "        return logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.9189, -0.9189])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = torch.zeros(2,1)\n",
    "cov = torch.eye(2)\n",
    "m = MultivariateNormal(mean, cov)\n",
    "x = torch.tensor([0.,0.]) \n",
    "m.log_prob(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = decoder().to(device)\n",
    "q_z0 = q_z0().to(device)\n",
    "r_v = r_v().to(device)\n",
    "q_v = q_v().to(device)\n",
    "mass_diag = torch.randn(z_dim, requires_grad=True)\n",
    "#mass = torch.randn(z_dim, requires_grad=True)\n",
    "#mass = torch.eye(z_dim, requires_grad=True)\n",
    "#mass_cuda = mass.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mass = Variable(torch.randn(batch_size, 100).cuda(), requires_grad=True)\n",
    "#mass_diag = torch.randn(z_dim, requires_grad=True)\n",
    "#mass_matrix = torch.diag(mass_diag).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_bound(decoder, q_z0, r_v, q_v, data, mass_diag, T):\n",
    "    data = data.to(device)\n",
    "    mu_z0, logvar_z0 = q_z0(data)\n",
    "    var_z0 = torch.exp(logvar_z0)\n",
    "    #print(logvar_z0.shape)\n",
    "\n",
    "    # sample z0\n",
    "    z0 = reparameterize(mu_z0, logvar_z0)\n",
    "    #print(\"z0: \" + str(z0.shape))\n",
    "\n",
    "    # get joint probaility p(x, z0)\n",
    "    log_prior_z0 = log_prior(z0)\n",
    "    #print(\"log_prior_z0: \" + str(log_prior_z0.shape))\n",
    "    decoder_output = decoder(z0)\n",
    "    #print(\"decoder_output: \" + str(decoder_output.shape))\n",
    "    log_likelihood = 0. - F.binary_cross_entropy(decoder_output, data.view(-1, 784), size_average=False, reduce=False)\n",
    "    #print(\"log_likelihood: \" + str(log_likelihood.shape))\n",
    "    log_likelihood = torch.sum(log_likelihood, dim = 1)\n",
    "    #print(\"log_likelihood: \" + str(log_likelihood.shape))\n",
    "    log_joint = log_prior_z0 + log_likelihood\n",
    "    #print(\"log_joint: \" + str(log_joint.shape))\n",
    "\n",
    "    # get log q_z0\n",
    "    log_q_z0 = torch.zeros(0).cuda()\n",
    "    for i in range(batch_size):\n",
    "        one_cov = torch.diag(var_z0[i])\n",
    "        #m = MultivariateNormal(mu_z0[i], one_cov)\n",
    "        #one_q_z0 = m.log_prob(z0[i]).view(1)\n",
    "        one_q_z0 = multivariate_normal_logpdf(mu_z0[i], one_cov, z0[i])\n",
    "        #print(\"one q z0: \" + str(one_q_z0))\n",
    "        log_q_z0 = torch.cat((log_q_z0,one_q_z0),0)\n",
    "    #print(\"log_q_z0: \" + str(log_q_z0.shape))\n",
    "\n",
    "\n",
    "    # initial L for 128 samples\n",
    "    L = log_joint - log_q_z0\n",
    "    L = torch.sum(L)\n",
    "    #print(\"L \"+str(L))\n",
    "    #print(L.shape)\n",
    "\n",
    "    #print(\"====================================\")\n",
    "    for i in range(T):\n",
    "         # sample v_t'(v1)\n",
    "        logvar_v1 = q_v(data)\n",
    "        var_v1 = torch.exp(logvar_v1)\n",
    "        #print(\"logvar_v1: \" + str(logvar_v1.shape))\n",
    "        mu_v1 = torch.zeros(logvar_v1.shape[0], logvar_v1.shape[1]).cuda()\n",
    "        v1 = reparameterize(mu_v1, logvar_v1)\n",
    "        #print(\"v1: \"+str(v1.shape))\n",
    "\n",
    "        # get q_v1\n",
    "        log_q_v1 = torch.zeros(0).cuda()\n",
    "        for i in range(batch_size):\n",
    "            one_cov = torch.diag(var_v1[i])\n",
    "            #m = MultivariateNormal(mu_v1[i], one_cov)\n",
    "            #one_q_v1 = m.log_prob(v1[i]).view(1)\n",
    "            one_q_v1 = multivariate_normal_logpdf(mu_v1[i], one_cov, v1[i])\n",
    "            log_q_v1 = torch.cat((log_q_v1,one_q_v1),0)\n",
    "        #print(\"log_q_v1: \"+str(log_q_v1.shape))\n",
    "\n",
    "        log_joint_t = torch.zeros(0).cuda() # list of all the joint\n",
    "        log_r_vt = torch.zeros(0).cuda()\n",
    "        alpha = torch.tensor([0.]).cuda() # lower bound for each batch (128 samples)\n",
    "        for j in range(batch_size):\n",
    "            def energy_function(z, cache):\n",
    "                z.retain_grad()\n",
    "                z = z.view(1, z.shape[0])\n",
    "                z = z.cuda()\n",
    "                one_log_prior = log_prior(z)\n",
    "                decoder_output = decoder(z)\n",
    "                one_log_likelihood = 0. - F.binary_cross_entropy(decoder_output, data.view(-1, 784)[j], size_average=False, reduce=False)\n",
    "                #print(one_log_likelihood.shape)\n",
    "                one_log_likelihood = torch.sum(one_log_likelihood, dim = 1)\n",
    "                one_log_joint = one_log_prior + one_log_likelihood\n",
    "                return 0 - one_log_joint\n",
    "            sampler = IsotropicHmcSampler(energy_function, energy_grad=None, prng=None,\n",
    "                                          mom_resample_coeff=1., dtype=np.float64)\n",
    "            init = torch.zeros(z_dim).cuda()\n",
    "            mass_matrix = torch.diag(mass_diag)\n",
    "            mass_matrix.cuda()\n",
    "            pos_samples, mom_samples, ratio = sampler.get_samples(init, 0.1, 3, 2, mass_matrix, mom = v1[j].view(z_dim))\n",
    "            #print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~`\")\n",
    "            #print(pos_samples[1].shape)\n",
    "\n",
    "            # get joint probaility p(x, zt)\n",
    "            zt = pos_samples[1].cuda()\n",
    "            vt = mom_samples[1].cuda()\n",
    "            zt = zt.view(1, zt.shape[0])\n",
    "            vt = vt.view(vt.shape[0])\n",
    "\n",
    "            # get joint probaility p(x, zt)\n",
    "            one_log_prior_zt = log_prior(zt)\n",
    "            #print(\"one_log_prior_zt: \" + str(one_log_prior_zt.shape))\n",
    "            one_decoder_output_t = decoder(zt)\n",
    "            #print(\"one_decoder_output_t: \" + str(one_decoder_output_t.shape))\n",
    "            one_log_likelihood_t = 0. - F.binary_cross_entropy(one_decoder_output_t, data.view(-1, 784)[j], size_average=False, reduce=False)\n",
    "            one_log_likelihood_t = torch.sum(one_log_likelihood_t, dim = 1)\n",
    "            #print(\"one_log_likelihood_t: \" + str(one_log_likelihood_t.shape))\n",
    "            one_log_joint_t = one_log_prior_zt + one_log_likelihood_t\n",
    "            #print(\"one_log_joint_t: \" + str(one_log_joint_t.shape))\n",
    "            log_joint_t = torch.cat((log_joint_t, one_log_joint_t), 0)\n",
    "\n",
    "            # get r_vt\n",
    "            d = data.view(-1, 784)[j].view(1, 784)\n",
    "            one_new_data = torch.cat((d, zt), 1) # append data with zt\n",
    "            one_mu_vt, one_logvar_vt = r_v(one_new_data)\n",
    "            one_var_vt = torch.exp(one_logvar_vt)\n",
    "            one_mu_vt = one_mu_vt.view(one_mu_vt.shape[1])\n",
    "            one_cov = torch.diag(one_var_vt.view(one_var_vt.shape[1]))\n",
    "            #m = MultivariateNormal(one_mu_vt, one_cov)\n",
    "            #one_log_r_vt = m.log_prob(vt).view(1)\n",
    "            #one_log_r_vt = multivariate_normal_logpdf(one_mu_vt, one_cov, vt)\n",
    "            log_r_vt = torch.cat((log_r_vt, one_log_r_vt), 0)\n",
    "            \n",
    "\n",
    "            # get L for each sample\n",
    "            one_log_alpha = log_joint_t[j] + log_r_vt[j] - log_joint[j] - log_q_v1[j]\n",
    "            #print(\"one log alpha: \"+str(one_log_alpha))\n",
    "            #one_log_alpha = torch.log(one_alpha)\n",
    "            L = L + one_log_alpha\n",
    "            #alpha = alpha + one_alpha\n",
    "        #L = L + torch.log(alpha)\n",
    "\n",
    "    #print(\"~~~~~~~~~~~~~~~~~~~ new L \" + str(L) + \" ~~~~~~~~~~~~~~~~~~~\")\n",
    "    return L    \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++ 0 ++++++++++\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1474: UserWarning: Using a target size (torch.Size([784])) that is different to the input size (torch.Size([1, 784])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++ 1 ++++++++++\n",
      "++++++++++ 2 ++++++++++\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "MAGMA potrf : A(1,1) is 0, A cannot be factorized at c:\\programdata\\miniconda3\\conda-bld\\pytorch_1524546354046\\work\\aten\\src\\thc\\generic/THCTensorMathMagma.cu:579",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-8c87df58302b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0moptimizer1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0moptimizer2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mL\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlower_bound\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mq_z0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr_v\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mq_v\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmass_diag\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mL\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-136f8d5a7536>\u001b[0m in \u001b[0;36mlower_bound\u001b[1;34m(decoder, q_z0, r_v, q_v, data, mass_diag, T)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mone_cov\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar_z0\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMultivariateNormal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmu_z0\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mone_cov\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0mone_q_z0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz0\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[1;31m#one_q_z0 = multivariate_normal_logpdf(mu_z0[i], one_cov, z0[i])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[1;31m#print(\"one q z0: \" + str(one_q_z0))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\distributions\\multivariate_normal.py\u001b[0m in \u001b[0;36mlog_prob\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m    180\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_sample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[0mdiff\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mM\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_batch_mahalanobis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscale_tril\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiff\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[0mlog_det\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_batch_diag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscale_tril\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m0.5\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mM\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlog_det\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\distributions\\utils.py\u001b[0m in \u001b[0;36m__get__\u001b[1;34m(self, instance, obj_type)\u001b[0m\n\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minstance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m         \u001b[0msetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\distributions\\multivariate_normal.py\u001b[0m in \u001b[0;36mscale_tril\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mlazy_property\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mscale_tril\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 151\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_batch_potrf_lower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcovariance_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mlazy_property\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\distributions\\multivariate_normal.py\u001b[0m in \u001b[0;36m_batch_potrf_lower\u001b[1;34m(bmat)\u001b[0m\n\u001b[0;32m     44\u001b[0m     \"\"\"\n\u001b[0;32m     45\u001b[0m     \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbmat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m     \u001b[0mcholesky\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpotrf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mupper\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mC\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbmat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcholesky\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbmat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\distributions\\multivariate_normal.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     44\u001b[0m     \"\"\"\n\u001b[0;32m     45\u001b[0m     \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbmat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m     \u001b[0mcholesky\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpotrf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mupper\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mC\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbmat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcholesky\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbmat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: MAGMA potrf : A(1,1) is 0, A cannot be factorized at c:\\programdata\\miniconda3\\conda-bld\\pytorch_1524546354046\\work\\aten\\src\\thc\\generic/THCTensorMathMagma.cu:579"
     ]
    }
   ],
   "source": [
    "params1 = list(decoder.parameters())+list(q_z0.parameters())+list(r_v.parameters())+list(q_v.parameters())\n",
    "optimizer1 = optim.Adam(params1, lr=1e-3)\n",
    "optimizer2 = optim.Adam([mass_diag], lr=1e-3)\n",
    "\n",
    "for batch_idx, (data, _) in enumerate(train_loader):\n",
    "    print(\"++++++++++ \" + str(batch_idx) + \" ++++++++++\")\n",
    "    optimizer1.zero_grad()\n",
    "    optimizer2.zero_grad()\n",
    "    L = lower_bound(decoder, q_z0, r_v, q_v, data, mass_diag, 1)\n",
    "    loss = 0. - L\n",
    "    loss.backward()\n",
    "    optimizer1.step()\n",
    "    optimizer2.step()\n",
    "print(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "params argument given to the optimizer should be an iterable of Tensors or dicts, but got torch.FloatTensor",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-143b7071f5f2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m#x = Variable(torch.randn(5))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\optim\\sgd.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, params, lr, momentum, dampening, weight_decay, nesterov)\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnesterov\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmomentum\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mdampening\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Nesterov momentum requires a momentum and zero dampening\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSGD\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setstate__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\optim\\optimizer.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, params, defaults)\u001b[0m\n\u001b[0;32m     29\u001b[0m             raise TypeError(\"params argument given to the optimizer should be \"\n\u001b[0;32m     30\u001b[0m                             \u001b[1;34m\"an iterable of Tensors or dicts, but got \"\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m                             torch.typename(params))\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: params argument given to the optimizer should be an iterable of Tensors or dicts, but got torch.FloatTensor"
     ]
    }
   ],
   "source": [
    "#params = mass_diag\n",
    "\n",
    "\n",
    "#optimizer = optim.Adam(params, lr=1e-3)\n",
    "\n",
    "w = torch.randn([3,5], requires_grad=True)\n",
    "b = torch.randn(3, requires_grad=True)\n",
    "#x = Variable(torch.randn(5))\n",
    "\n",
    "optimizer = optim.SGD([w], lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([400, 20])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(decoder.parameters())\n",
    "params[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(decoder.parameters())[0]\n",
    "#list(mass_diag)[0]\n",
    "mass_diag.is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 784])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt = torch.ones(1, 784).cuda()\n",
    "print(tt.shape)\n",
    "torch.sum(tt, dim=1)\n",
    "tt.is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[0.1, 0.1],[0.1,0.1],[0.1,0.1]])\n",
    "y = torch.tensor([[0.5, 0.5],[0.5,0.5],[1.,1.]])\n",
    "L = F.binary_cross_entropy(y, x, size_average=False, reduce=False)\n",
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Lapack Error getrf : U(2,2) is 0, U is singular at c:\\programdata\\miniconda3\\conda-bld\\pytorch_1524546354046\\work\\aten\\src\\th\\generic/THTensorLapack.c:514",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-dee977365fee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: Lapack Error getrf : U(2,2) is 0, U is singular at c:\\programdata\\miniconda3\\conda-bld\\pytorch_1524546354046\\work\\aten\\src\\th\\generic/THTensorLapack.c:514"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[0.1, 0.1],[0.1,0.1]])\n",
    "torch.inverse(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  1.3863,   1.3863,  49.7358])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(L, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  0,  0],\n",
       "        [ 0,  2,  0],\n",
       "        [ 0,  0,  3]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.diag(torch.tensor([1, 2, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.0050])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.normal(torch.tensor([0.]),torch.tensor([1.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  0.],\n",
       "        [ 0.,  1.]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eye(2, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3646,  0.7910,  0.5176]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x.view(1, 3)\n",
    "y.view(1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "for i in range(500):\n",
    "    x.append(reparameterize(torch.tensor([0.]), torch.tensor([1.])).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a17b3eba90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(x)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
